{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Training\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html). The dataset is then used to train Graph Neural Networks as a first evaluation based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#learning-methods-on-graphs).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_networks.dynamic_edge import DynamicEdge\n",
    "from pg_networks.gcn import GCN\n",
    "from pg_networks.sg import SG\n",
    "import src.config as cfg\n",
    "from src.davis_2016 import DAVIS2016\n",
    "from src.solver import Solver\n",
    "from src.vis_utils import plot_img_with_contour_and_translation, plot_translations, plot_loss, \\\n",
    "                          plot_combo_img\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "#0: bear\n",
      "Model available\n",
      "Create new OSVOS model...\n",
      "Constructing OSVOS architecture..\n",
      "Initializing weights..\n",
      "#2: bmx-bumps\n",
      "Model available\n",
      "Create new OSVOS model...\n",
      "Constructing OSVOS architecture..\n",
      "Initializing weights..\n",
      "#4: boat\n",
      "Model available\n",
      "Create new OSVOS model...\n",
      "Constructing OSVOS architecture..\n",
      "Initializing weights..\n"
     ]
    }
   ],
   "source": [
    "train = DAVIS2016(cfg.PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                  cfg.CONTOURS_FOLDERS_PATH, cfg.IMAGES_AUGMENTED_FOLDERS_PATH, cfg.TRANSLATIONS_FOLDERS_PATH, \n",
    "                  cfg.LAYER, cfg.K, cfg.EPOCHS_WO_AVEGRAD, cfg.AUGMENTATION_COUNT,\n",
    "                  cfg.SKIP_SEQUENCES, cfg.TRAIN_SEQUENCES[:cfg.NUM_SEQUENCES], cfg.VAL_SEQUENCES[:cfg.NUM_SEQUENCES],\n",
    "                  train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DAVIS2016(cfg.PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                cfg.CONTOURS_FOLDERS_PATH, cfg.IMAGES_AUGMENTED_FOLDERS_PATH, cfg.TRANSLATIONS_FOLDERS_PATH, \n",
    "                cfg.LAYER, cfg.K, cfg.EPOCHS_WO_AVEGRAD, 1,\n",
    "                cfg.SKIP_SEQUENCES, cfg.TRAIN_SEQUENCES[:cfg.NUM_SEQUENCES], cfg.VAL_SEQUENCES[:cfg.NUM_SEQUENCES],\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train size: %i\" % len(train))\n",
    "print(\"Val size: %i\" % len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_display = 5\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, len(train))\n",
    "    data = train[rand_i]\n",
    "    \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_img_with_contour_and_translation(data.img, data.contour, data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[0]\n",
    "\n",
    "model = GCN(in_channels=data.num_features, \n",
    "            out_channels=data.y.shape[1])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 80\n",
    "num_val = 20\n",
    "\n",
    "overfit_train_loader = DataLoader(train, batch_size=16, \n",
    "                                  shuffle=False, sampler=SequentialSampler(range(num_train)))\n",
    "overfit_val_loader = DataLoader(train, batch_size=1, \n",
    "                                shuffle=False, sampler=SequentialSampler(range(num_val)))\n",
    "\n",
    "# Load model and run the solver\n",
    "overfit_model = GCN(in_channels=data.num_features, \n",
    "                    out_channels=data.y.shape[1])\n",
    "\n",
    "overfit_solver = Solver(optim_args={\"lr\": LEARNING_RATE})\n",
    "overfit_solver.train(overfit_model, overfit_train_loader, overfit_val_loader,\n",
    "                     num_epochs=5, log_nth=100, verbose=True)\n",
    "\n",
    "#Save model\n",
    "torch.save(model.state_dict(), 'pg_models/Bear_overfit_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_model.cpu()\n",
    "overfit_model.double()\n",
    "overfit_model.eval()\n",
    "num_to_display = 2\n",
    "\n",
    "for i in range(num_to_display):\n",
    "\n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, num_val)\n",
    "    data = train[rand_i]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translation_pred = overfit_model(data)\n",
    "        \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_translations(data.img, data.contour, data.y, translation_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show test run for one example image\n",
    "original_img = 'DAVIS_2016/DAVIS/JPEGImages/480p/bear/00001.png'\n",
    "osvos_img = cv2.imread('OSVOS_PyTorch/models/Results/bear/00001.png')\n",
    "contour_0 = train[0].contour\n",
    "translation_0_1_pred = overfit_model(train[0])\n",
    "contour_1_pred = contour_0.type(torch.DoubleTensor).add(translation_0_1_pred)\n",
    "\n",
    "plot_combo_img(contour_1_pred, osvos_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Load model and run the solver\n",
    "model = GCN(in_channels=train[0].num_features, \n",
    "            out_channels=train[0].y.shape[1])\n",
    "\n",
    "solver = Solver(optim_args={\"lr\": cfg.LEARNING_RATE,\n",
    "                            \"weight_decay\": cfg.WEIGHT_DECAY})\n",
    "\n",
    "solver.train(model, train_loader, val_loader,\n",
    "             num_epochs=cfg.NUM_EPOCHS, log_nth=100, verbose=True)\n",
    "\n",
    "torch.save(model.state_dict(), 'pg_models/trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display trained outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model.double()\n",
    "model.eval()\n",
    "num_to_display = 5\n",
    "\n",
    "for i in range(num_to_display):\n",
    "\n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, len(val))\n",
    "    data = val[rand_i]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translation_pred = model(data)\n",
    "    \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_translations(data.img, data.contour, data.y, translation_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "learning_rates = [1e-2, 1e-4, 1e-6]\n",
    "weight_decays = [1e-0, 1e-2, 1e-4]\n",
    "\n",
    "best_model = None\n",
    "best_loss = 1e10\n",
    "\n",
    "i = 0\n",
    "for learning_rate in learning_rates:\n",
    "    if i == 0: break\n",
    "    for weight_decay in weight_decays:\n",
    "        model = GCN(in_channels=train[0].num_features, \n",
    "                    out_channels=train[0].y.shape[1])\n",
    "        solver = Solver(optim_args={\"lr\": LEARNING_RATE,\n",
    "                            \"weight_decay\": WEIGHT_DECAY})\n",
    "        solver.train(model, train_loader, val_loader,\n",
    "             num_epochs=20, log_nth=100, verbose=False)\n",
    "\n",
    "        # Predict on the validation set\n",
    "        val_loss = max(solver.val_loss_history)\n",
    "        print('Hyperparamter Tuning #', i + 1,\n",
    "                'lr: ', learning_rate,\n",
    "                'wd: ', weight_decay,\n",
    "                'val_loss: ', val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
