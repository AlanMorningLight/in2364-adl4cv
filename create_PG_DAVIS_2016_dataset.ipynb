{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PyTorch Geometric DAVIS 2016 Dataset\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'\n",
    "PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH = 'PyTorch_Geometric_Datasets/DAVIS_2016'\n",
    "\n",
    "SKIP_SEQUENCES = ['bmx-trees', 'bus', 'cows', 'dog-agility', 'horsejump-high', \n",
    "                  'horsejump-low', 'kite-walk', 'lucia', 'libby', 'motorbike',\n",
    "                  'paragliding', 'rhino', 'scooter-gray', 'swing']\n",
    "K = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_attribute(contour, edge_index):\n",
    "    '''Returns an edge feature matrix of shape [num_edges, num_edge_features]\n",
    "       containing the distances between the node each edge connects.'''\n",
    "    \n",
    "    edge_index = edge_index.numpy()\n",
    "    edge_index = edge_index.T\n",
    "    \n",
    "    edge_attr = []\n",
    "    for edge in edge_index:\n",
    "        contour_point_0 = contour[edge[0]] \n",
    "        contour_point_1 = contour[edge[1]]\n",
    "        dist = np.linalg.norm(contour_point_0-contour_point_1)\n",
    "        edge_attr.append([dist])\n",
    "    \n",
    "    edge_atrr = np.array(edge_attr)\n",
    "    return torch.from_numpy(edge_atrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(contour, translation):\n",
    "    '''Returns data object.'''\n",
    "    \n",
    "    # x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "    # The feature of each node is the OSVOS feature vector of the next frame\n",
    "    # TODO \n",
    "    # x = get_OSVOS_feature_vectors(contour)\n",
    "    x = None\n",
    "\n",
    "    # edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "    # Each node should be connected to its K nearest neighbours\n",
    "    positions = torch.from_numpy(contour)\n",
    "    edge_index = knn_graph(positions, K)\n",
    "    edge_index = to_undirected(edge_index)\n",
    "\n",
    "    # edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "    # The feature of each edge is the distance between the two nodes it connects\n",
    "    edge_attr = get_edge_attribute(contour, edge_index)\n",
    "\n",
    "    # y: Target to train against (may have arbitrary shape)\n",
    "    # The target of each node is the displacement of the node between the current and the next frame\n",
    "    y = torch.from_numpy(translation)\n",
    "\n",
    "    # Create data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InMemoryDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAVIS2016(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, contours_folders_path,):\n",
    "        super(DAVIS2016, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_file_names = ['Contours', 'Translations']\n",
    "        return raw_file_names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Copy Contours folder to raw_dir\n",
    "        raw_dir_contours = os.path.join(self.raw_dir, 'Contours')\n",
    "        copy_tree(CONTOURS_FOLDERS_PATH, raw_dir_contours)\n",
    "        \n",
    "        # Copy Translations folder to raw_dir\n",
    "        raw_dir_translations = os.path.join(self.raw_dir, 'Translations')\n",
    "        copy_tree(TRANSLATIONS_FOLDERS_PATH, raw_dir_translations)\n",
    "        \n",
    "    def process(self):\n",
    "        # Get paths to Contours and Translations\n",
    "        raw_path_contours, raw_path_translations = self.raw_paths\n",
    "        \n",
    "        # Get list of folders (there is one for each sequence)\n",
    "        translations_folders_list = os.listdir(raw_path_translations)\n",
    "        \n",
    "        # Create empty data list to which Data objects will be added\n",
    "        data_list = []\n",
    "        \n",
    "        # Iterate through folders \n",
    "        for i, folder in enumerate(translations_folders_list):\n",
    "            \n",
    "            # Skip if it is a bad sequence\n",
    "            if (folder in SKIP_SEQUENCES): continue\n",
    "            \n",
    "            # Debug\n",
    "            # if (i > 2): break\n",
    "            \n",
    "            print('#{}: {}'.format(i, folder))\n",
    "            \n",
    "            # Get paths to current sequence in Contours and Translations folders\n",
    "            contours_folder_path = os.path.join(raw_path_contours, folder)\n",
    "            translations_folder_path = os.path.join(raw_path_translations, folder)\n",
    "            \n",
    "            # Get list of translations (one for each frame in the sequence)\n",
    "            translations = os.listdir(translations_folder_path)\n",
    "            translations.sort()\n",
    "            \n",
    "            # Iterate through translations\n",
    "            for j, translation in enumerate(translations):\n",
    "                \n",
    "                # Debug\n",
    "                # if (j > 4): break\n",
    "                \n",
    "                # print('\\t#{}: {}'.format(j, translation))\n",
    "                \n",
    "                # Load corresponding contour\n",
    "                contour_path = os.path.join(contours_folder_path, translation)\n",
    "                contour = np.load(contour_path)\n",
    "                \n",
    "                # Load corresponding sequence\n",
    "                translation_path = os.path.join(translations_folder_path, translation)\n",
    "                translation = np.load(translation_path)\n",
    "                \n",
    "                # Get data and append it to data_list\n",
    "                data = create_data(contour, translation)\n",
    "                data_list.append(data)\n",
    "                \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "#1: drift-chicane\n",
      "#3: soapbox\n",
      "#4: breakdance\n",
      "#5: drift-turn\n",
      "#6: mallard-fly\n",
      "#9: scooter-black\n",
      "#10: breakdance-flare\n",
      "#12: elephant\n",
      "#14: rollerblade\n",
      "#15: dance-twirl\n",
      "#16: dance-jump\n",
      "#18: mallard-water\n",
      "#19: car-turn\n",
      "#22: car-shadow\n",
      "#23: paragliding-launch\n",
      "#24: stroller\n",
      "#25: bear\n",
      "#26: hockey\n",
      "#27: dog\n",
      "#28: boat\n",
      "#29: car-roundabout\n",
      "#30: soccerball\n",
      "#31: train\n",
      "#32: tennis\n",
      "#33: parkour\n",
      "#34: surf\n",
      "#35: kite-surf\n",
      "#37: drift-straight\n",
      "#38: flamingo\n",
      "#39: goat\n",
      "#41: hike\n",
      "#42: motocross-jump\n",
      "#44: motocross-bumps\n",
      "#47: camel\n",
      "#48: blackswan\n",
      "#49: bmx-bumps\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = DAVIS2016(root=PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
