{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Training\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html). The dataset is then used to train Graph Neural Networks as a first evaluation based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#learning-methods-on-graphs).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_networks.dynamic_edge import DynamicEdge\n",
    "from pg_networks.gcn import GCN\n",
    "from pg_networks.sg import SG\n",
    "import src.config as cfg\n",
    "from src.davis_2016 import DAVIS2016\n",
    "from src.solver import Solver\n",
    "from src.vis_utils import plot_img_with_contour_and_translation, plot_translations, plot_loss, \\\n",
    "                          plot_combo_img\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Create new OSVOS model...\n",
      "Constructing OSVOS architecture..\n",
      "Initializing weights..\n",
      "#0: bear\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "\tAugmentation #3\n",
      "\tAugmentation #4\n",
      "\tAugmentation #5\n",
      "#2: bmx-bumps\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "\tAugmentation #3\n",
      "\tAugmentation #4\n",
      "\tAugmentation #5\n",
      "#4: boat\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "\tAugmentation #3\n",
      "\tAugmentation #4\n",
      "\tAugmentation #5\n",
      "#6: breakdance-flare\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "\tAugmentation #3\n",
      "\tAugmentation #4\n",
      "\tAugmentation #5\n",
      "#7: bus\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "\tAugmentation #3\n",
      "\tAugmentation #4\n",
      "\tAugmentation #5\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = DAVIS2016(cfg.PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH,\n",
    "                  cfg.ANNOTATIONS_AUGMENTED_FOLDERS_PATH, cfg.CONTOURS_FOLDERS_PATH, \n",
    "                  cfg.IMAGES_AUGMENTED_FOLDERS_PATH, cfg.TRANSLATIONS_FOLDERS_PATH,\n",
    "                  cfg.PARENT_MODEL_PATH,\n",
    "                  cfg.LAYER, cfg.K, cfg.AUGMENTATION_COUNT,\n",
    "                  cfg.SKIP_SEQUENCES, cfg.TRAIN_SEQUENCES[:cfg.NUM_SEQUENCES], cfg.VAL_SEQUENCES[:cfg.NUM_SEQUENCES],\n",
    "                  train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c97f97ce1b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLAYER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS_WO_AVEGRAD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSKIP_SEQUENCES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_SEQUENCES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAL_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_SEQUENCES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   train=False)\n\u001b[0m",
      "\u001b[0;32m~/in2364-adl4cv/src/davis_2016.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, annotations_folders_path, contours_folders_path, images_folders_path, translations_folders_path, parent_model_path, layer, k, epochs_wo_avegrad, augmentation_count, skip_sequences, train_sequences, val_sequences, train, transform, pre_transform)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDAVIS2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "val = DAVIS2016(cfg.PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH,\n",
    "                cfg.ANNOTATIONS_AUGMENTED_FOLDERS_PATH, cfg.CONTOURS_FOLDERS_PATH, \n",
    "                cfg.IMAGES_AUGMENTED_FOLDERS_PATH, cfg.TRANSLATIONS_FOLDERS_PATH,\n",
    "                cfg.PARENT_MODEL_PATH,\n",
    "                cfg.LAYER, cfg.K, 0,\n",
    "                cfg.SKIP_SEQUENCES, cfg.TRAIN_SEQUENCES[:cfg.NUM_SEQUENCES], cfg.VAL_SEQUENCES[:cfg.NUM_SEQUENCES],\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train size: %i\" % len(train))\n",
    "print(\"Val size: %i\" % len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_display = 5\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, len(train))\n",
    "    data = train[rand_i]\n",
    "    \n",
    "    # Load corresponding image\n",
    "    processed_file_name = train.processed_file_names[rand_i]\n",
    "    folder = processed_file_name[:-11]\n",
    "    augmentation_count = processed_file_name[-10:-9]\n",
    "    file_name = processed_file_name[-8:-3]\n",
    "    \n",
    "    image_path = os.path.join(val.raw_paths[0], folder, augmentation_count,\n",
    "                                ('{}{}'.format(file_name, '.png')))\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_img_with_contour_and_translation(image, data.contour, data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[0]\n",
    "\n",
    "model = GCN(in_channels=data.num_features, \n",
    "            out_channels=data.y.shape[1])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 80\n",
    "num_val = 20\n",
    "\n",
    "overfit_train_loader = DataLoader(train, batch_size=16, \n",
    "                                  shuffle=False, sampler=SequentialSampler(range(num_train)))\n",
    "overfit_val_loader = DataLoader(train, batch_size=1, \n",
    "                                shuffle=False, sampler=SequentialSampler(range(num_val)))\n",
    "\n",
    "# Load model and run the solver\n",
    "overfit_model = GCN(in_channels=data.num_features, \n",
    "                    out_channels=data.y.shape[1])\n",
    "\n",
    "overfit_solver = Solver(optim_args={\"lr\": cfg.LEARNING_RATE})\n",
    "overfit_solver.train(overfit_model, overfit_train_loader, overfit_val_loader,\n",
    "                     num_epochs=5, log_nth=100, verbose=True)\n",
    "\n",
    "#Save model\n",
    "torch.save(model.state_dict(), 'pg_models/Bear_overfit_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_model.cpu()\n",
    "overfit_model.double()\n",
    "overfit_model.eval()\n",
    "num_to_display = 2\n",
    "\n",
    "for i in range(num_to_display):\n",
    "\n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, num_val)\n",
    "    data = train[rand_i]\n",
    "    \n",
    "    # Load corresponding image\n",
    "    processed_file_name = train.processed_file_names[rand_i]\n",
    "    folder = processed_file_name[:-11]\n",
    "    augmentation_count = processed_file_name[-10:-9]\n",
    "    file_name = processed_file_name[-8:-3]\n",
    "    \n",
    "    image_path = os.path.join(val.raw_paths[0], folder, augmentation_count,\n",
    "                                ('{}{}'.format(file_name, '.png')))\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translation_pred = overfit_model(data)\n",
    "        \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_translations(image, data.contour, data.y, translation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Load model and run the solver\n",
    "model = GCN(in_channels=train[0].num_features, \n",
    "            out_channels=train[0].y.shape[1])\n",
    "\n",
    "solver = Solver(optim_args={\"lr\": cfg.LEARNING_RATE,\n",
    "                            \"weight_decay\": cfg.WEIGHT_DECAY})\n",
    "\n",
    "solver.train(model, train_loader, val_loader,\n",
    "             num_epochs=cfg.NUM_EPOCHS, log_nth=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display trained outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model.double()\n",
    "model.eval()\n",
    "num_to_display = 10\n",
    "\n",
    "for i in range(num_to_display):\n",
    "\n",
    "    fig = plt.figure(figsize=(num_to_display*10,10))\n",
    "    \n",
    "    # randomly select a sample\n",
    "    rand_i = np.random.randint(0, len(val))\n",
    "    data = val[rand_i]\n",
    "    \n",
    "    # Load corresponding image\n",
    "    processed_file_name = val.processed_file_names[rand_i]\n",
    "    folder = processed_file_name[:-11]\n",
    "    augmentation_count = processed_file_name[-10:-9]\n",
    "    file_name = processed_file_name[-8:-3]\n",
    "    \n",
    "    image_path = os.path.join(val.raw_paths[0], folder, augmentation_count,\n",
    "                                ('{}{}'.format(file_name, '.png')))\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        translation_pred = model(data)\n",
    "    \n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(rand_i))\n",
    "    \n",
    "    plot_translations(image, data.contour, data.y, translation_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "learning_rates = [1e-2, 1e-4, 1e-6]\n",
    "weight_decays = [1e-0, 1e-2, 1e-4]\n",
    "\n",
    "best_model = None\n",
    "best_loss = 1e10\n",
    "\n",
    "i = 0\n",
    "for learning_rate in learning_rates:\n",
    "    if i == 0: break\n",
    "    for weight_decay in weight_decays:\n",
    "        model = GCN(in_channels=train[0].num_features, \n",
    "                    out_channels=train[0].y.shape[1])\n",
    "        solver = Solver(optim_args={\"lr\": LEARNING_RATE,\n",
    "                            \"weight_decay\": WEIGHT_DECAY})\n",
    "        solver.train(model, train_loader, val_loader,\n",
    "             num_epochs=20, log_nth=100, verbose=False)\n",
    "\n",
    "        # Predict on the validation set\n",
    "        val_loss = max(solver.val_loss_history)\n",
    "        print('Hyperparamter Tuning #', i + 1,\n",
    "                'lr: ', learning_rate,\n",
    "                'wd: ', weight_decay,\n",
    "                'val_loss: ', val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
