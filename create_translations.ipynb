{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create translations for contours of DAVIS 2016\n",
    "\n",
    "In this notebook, the translations between the  points of two consecutive contours are computed and the number of contour points is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_indices(distances):\n",
    "    '''Returns a (N, 2) array containing the indices of the smallest distances\n",
    "       sorted in ascending order given a (N, N) distance matrix.'''\n",
    "    \n",
    "    # Get indices that sort array by minimal distance\n",
    "    min_indices = np.argsort(distances, axis=None)\n",
    "\n",
    "    # Turn array of flat indices into a tuple of coordinate arrays\n",
    "    min_indices = np.unravel_index(min_indices, distances.shape)\n",
    "\n",
    "    # Turn tuple of arrays into array of coordinate arrays\n",
    "    min_indices = np.array([min_indices[0], min_indices[1]])\n",
    "\n",
    "    # Transpose array\n",
    "    min_indices = min_indices.T\n",
    "\n",
    "    return min_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corresponding_points(contour_0, contour_1):\n",
    "    '''Returns a (N, 2) array containing the matching of the closest contour \n",
    "       points given two contours.'''\n",
    "    \n",
    "    # Get distance matrix between every point of contour_0 and contour_1\n",
    "    distances = spatial.distance.cdist(contour_0, contour_1, 'euclidean')\n",
    "    \n",
    "    # Get indices of the smallest distances\n",
    "    min_indices = get_min_indices(distances)\n",
    "    \n",
    "    corresponding_points = np.empty([0, 2], int)\n",
    "    forbidden_points_0 = set()\n",
    "    forbidden_points_1 = set()\n",
    "    \n",
    "    for min_index in min_indices:\n",
    "        if ((min_index[0] in forbidden_points_0) or (min_index[1] in forbidden_points_1)):\n",
    "            continue\n",
    "        else:\n",
    "            corresponding_points = np.append(corresponding_points, min_index.reshape([1,2]), axis=0)\n",
    "            forbidden_points_0.add(min_index[0])\n",
    "            forbidden_points_1.add(min_index[1])\n",
    "    \n",
    "    # Sort corresponding points by first column\n",
    "    corresponding_points = corresponding_points[corresponding_points[:,0].argsort()]\n",
    "    \n",
    "    return corresponding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translations(contour_0, contour_1):\n",
    "    '''Returns the translations for each point in contour_0 to contour_1.'''\n",
    "    \n",
    "    corresponding_points = get_corresponding_points(contour_0, contour_1)\n",
    "    \n",
    "    translations = np.empty([0, 2], int)\n",
    "    \n",
    "    for point in corresponding_points:\n",
    "        \n",
    "        translation = np.subtract(contour_1[point[1]], contour_0[point[0]])\n",
    "        translations = np.append(translations, translation.reshape([1,2]), axis=0)\n",
    "    \n",
    "    return translations, corresponding_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translations_for_all_contours(contours_folders_path,\n",
    "                                         translations_folders_path):\n",
    "    \n",
    "    contours_folders_list = os.listdir(contours_folders_path)\n",
    "\n",
    "    # Iterate through folders\n",
    "    for i, folder in enumerate(contours_folders_list):\n",
    "\n",
    "        # if (i > 0): break\n",
    "\n",
    "        print('#{}: {}'.format(i, folder))\n",
    "\n",
    "        # Create folder to save translations\n",
    "        translations_folder = os.path.join(translations_folders_path, folder)\n",
    "        if not os.path.exists(translations_folder):\n",
    "            os.makedirs(translations_folder)\n",
    "\n",
    "        # Get list of contours\n",
    "        contours = os.listdir(os.path.join(contours_folders_path, folder))\n",
    "        if '.ipynb_checkpoints' in contours:\n",
    "            contours.remove('.ipynb_checkpoints')\n",
    "        contours.sort()\n",
    "            \n",
    "        # Iterate through annotations\n",
    "        for j, contour in enumerate(contours):\n",
    "\n",
    "            # if (j > 0): break\n",
    "                \n",
    "            # Load contours\n",
    "            contour_0_path = os.path.join(contours_folders_path, folder, contours[j])\n",
    "            contour_0 = np.load(contour_paths[j])\n",
    "            \n",
    "            try:\n",
    "                contour_1_path = os.path.join(contours_folders_path, folder, contours[j+1])\n",
    "                contour_1 = np.load(contour_paths[j+1])\n",
    "            except IndexError as e:\n",
    "                break\n",
    "\n",
    "            # Compute translations\n",
    "            translations_0_1, corresponding_points = get_translations(contour_0, contour_1)\n",
    "            \n",
    "            # Update contour_1 so that it has same amount of points as contour_0\n",
    "            corresponding_points = corresponding_points.T \n",
    "            contour_1 = contour_1[corresponding_points[1]] \n",
    "\n",
    "            # Save contour_1\n",
    "            np.save(contour_paths[j+1], contour_1)\n",
    "            \n",
    "            # Save translations\n",
    "            np.save(os.path.join(translations_folder, contour[:5]), translations_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: swing\n",
      "#1: drift-chicane\n",
      "#2: lucia\n",
      "#3: soapbox\n"
     ]
    }
   ],
   "source": [
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'\n",
    "\n",
    "create_translations_for_all_contours(CONTOURS_FOLDERS_PATH,\n",
    "                                     TRANSLATIONS_FOLDERS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  4],\n",
       "       [ 8,  5],\n",
       "       [-5,  6],\n",
       "       [-5,  2],\n",
       "       [-7, -6],\n",
       "       [ 4, -1],\n",
       "       [11, -2],\n",
       "       [ 7, -1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('DAVIS_2016/DAVIS/Translations/480p/swing/00000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
