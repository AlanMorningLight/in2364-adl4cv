{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Translations for DAVIS 2016 Contours\n",
    "\n",
    "In this notebook translations between points of two consecutive contours are saved as numpy arrarys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "For two consecutive contours from the annotations of the DAVIS 2016 dataset, the closest points are matched and then the translations are calculated and saved as a numpy array. Initially, there are twice as many contour points on the second contour, so that each point from the first contour finds a close neighbour. After the matching, the points from the second contour that are not matched get discarded and the contour is saved again as a numpy array.\n",
    "\n",
    "In this picture, the points from the first contour are in red and the one from the second contour in green. The small blue arrows represent the translations of each point.\n",
    "\n",
    "<img src=\"Images/bear_annotation_translations.jpeg\" alt=\"bear_annotation_translations\" width=\"512\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_indices(distances):\n",
    "    '''Returns a (N, 2) array containing the indices of the smallest distances\n",
    "       sorted in ascending order given a (N, N) distance matrix.'''\n",
    "    \n",
    "    # Get indices that sort array by minimal distance\n",
    "    min_indices = np.argsort(distances, axis=None)\n",
    "\n",
    "    # Turn array of flat indices into a tuple of coordinate arrays\n",
    "    min_indices = np.unravel_index(min_indices, distances.shape)\n",
    "\n",
    "    # Turn tuple of arrays into array of coordinate arrays\n",
    "    min_indices = np.array([min_indices[0], min_indices[1]])\n",
    "\n",
    "    # Transpose array\n",
    "    min_indices = min_indices.T\n",
    "\n",
    "    return min_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corresponding_points(contour_0, contour_1):\n",
    "    '''Returns a (N, 2) array containing the matching of the closest contour \n",
    "       points given two contours.'''\n",
    "    \n",
    "    # Get distance matrix between every point of contour_0 and contour_1\n",
    "    distances = spatial.distance.cdist(contour_0, contour_1, 'euclidean')\n",
    "    \n",
    "    # Get indices of the smallest distances\n",
    "    min_indices = get_min_indices(distances)\n",
    "    \n",
    "    # Compute corresponding points. Each point can only be matched once\n",
    "    corresponding_points = np.empty([0, 2], int)\n",
    "    forbidden_points_0 = set()\n",
    "    forbidden_points_1 = set()\n",
    "    \n",
    "    for min_index in min_indices:\n",
    "        if ((min_index[0] in forbidden_points_0) or \n",
    "            (min_index[1] in forbidden_points_1)):\n",
    "            continue\n",
    "        else:\n",
    "            corresponding_points = np.append(corresponding_points, \n",
    "                                             min_index.reshape([1,2]),\n",
    "                                             axis=0)\n",
    "            forbidden_points_0.add(min_index[0])\n",
    "            forbidden_points_1.add(min_index[1])\n",
    "    \n",
    "    # Sort corresponding points by first column\n",
    "    corresponding_points = corresponding_points[corresponding_points[:,0].argsort()]\n",
    "    \n",
    "    return corresponding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translations(contour_0, contour_1):\n",
    "    '''Returns the translations for each point in contour_0 to contour_1.'''\n",
    "    \n",
    "    # Get corresponding points\n",
    "    corresponding_points = get_corresponding_points(contour_0, contour_1)\n",
    "    \n",
    "    # Compute translations\n",
    "    translations = np.empty([0, 2], int)\n",
    "    \n",
    "    for point in corresponding_points:\n",
    "        translation = np.subtract(contour_1[point[1]], contour_0[point[0]])\n",
    "        translations = np.append(translations, translation.reshape([1,2]), axis=0)\n",
    "    \n",
    "    return translations, corresponding_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translations_for_all_contours(contours_folders_path,\n",
    "                                         translations_folders_path):\n",
    "    '''Creates translations for contours and saves them as numpy arrays.'''\n",
    "    \n",
    "    # Get list of contours folder (there is one for each sequence)\n",
    "    contours_folders_list = os.listdir(contours_folders_path)\n",
    "\n",
    "    # Iterate through folders\n",
    "    for i, folder in enumerate(contours_folders_list):\n",
    "        \n",
    "        # Debug\n",
    "        #if (i > 1): break\n",
    "\n",
    "        print('#{}: {}'.format(i, folder))\n",
    "\n",
    "        # Create folder to save translations\n",
    "        translations_folder = os.path.join(translations_folders_path, folder)\n",
    "        if not os.path.exists(translations_folder):\n",
    "            os.makedirs(translations_folder)\n",
    "\n",
    "        # Get list of contours (there is one for each frame)\n",
    "        contours = os.listdir(os.path.join(contours_folders_path, folder))\n",
    "        if '.ipynb_checkpoints' in contours:\n",
    "            contours.remove('.ipynb_checkpoints')\n",
    "        contours.sort()\n",
    "            \n",
    "        # Iterate through annotations\n",
    "        for j, contour in enumerate(contours):\n",
    "\n",
    "            # Debug\n",
    "            #if (j > 1): break\n",
    "                \n",
    "            # Load contours\n",
    "            contour_0_path = os.path.join(contours_folders_path, folder, contours[j])\n",
    "            contour_0 = np.load(contour_0_path)\n",
    "            \n",
    "            try:\n",
    "                contour_1_path = os.path.join(contours_folders_path, folder, contours[j+1])\n",
    "                contour_1 = np.load(contour_1_path)\n",
    "            except IndexError as e:\n",
    "                break\n",
    "\n",
    "            # Get translations\n",
    "            translations_0_1, corresponding_points = get_translations(contour_0, contour_1)\n",
    "            \n",
    "            # Update contour_1 so that it has same amount of points as contour_0\n",
    "            corresponding_points = corresponding_points.T \n",
    "            contour_1 = contour_1[corresponding_points[1]] \n",
    "\n",
    "            # Save contour_1\n",
    "            np.save(contour_1_path, contour_1)\n",
    "            \n",
    "            # Save translations\n",
    "            np.save(os.path.join(translations_folder, contour[:5]), translations_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: swing\n",
      "#1: drift-chicane\n",
      "#2: lucia\n",
      "#3: soapbox\n",
      "#4: breakdance\n",
      "#5: drift-turn\n",
      "#6: mallard-fly\n",
      "#7: motorbike\n",
      "#8: scooter-gray\n",
      "#9: scooter-black\n",
      "#10: breakdance-flare\n",
      "#11: bus\n",
      "#12: elephant\n",
      "#13: bmx-trees\n",
      "#14: rollerblade\n",
      "#15: dance-twirl\n",
      "#16: dance-jump\n",
      "#17: horsejump-high\n",
      "#18: mallard-water\n",
      "#19: car-turn\n",
      "#20: kite-walk\n",
      "#21: dog-agility\n",
      "#22: car-shadow\n",
      "#23: paragliding-launch\n",
      "#24: stroller\n",
      "#25: bear\n",
      "#26: hockey\n",
      "#27: dog\n",
      "#28: boat\n",
      "#29: car-roundabout\n",
      "#30: soccerball\n",
      "#31: train\n",
      "#32: tennis\n",
      "#33: parkour\n",
      "#34: surf\n",
      "#35: kite-surf\n",
      "#36: cows\n",
      "#37: drift-straight\n",
      "#38: flamingo\n",
      "#39: goat\n",
      "#40: rhino\n",
      "#41: hike\n",
      "#42: motocross-jump\n",
      "#43: horsejump-low\n",
      "#44: motocross-bumps\n",
      "#45: libby\n",
      "#46: paragliding\n",
      "#47: camel\n",
      "#48: blackswan\n",
      "#49: bmx-bumps\n"
     ]
    }
   ],
   "source": [
    "create_translations_for_all_contours(CONTOURS_FOLDERS_PATH,\n",
    "                                     TRANSLATIONS_FOLDERS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
