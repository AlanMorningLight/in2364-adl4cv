{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTOURS_FOLDERS_PATH = '../DAVIS_2016/DAVIS/Contours/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = '../DAVIS_2016/DAVIS/Translations/480p'\n",
    "\n",
    "SKIP_SEQUENCES = ['bmx-trees', 'bus', 'cows', 'dog-agility', 'horsejump-high', \n",
    "                  'horsejump-low', 'kite-walk', 'lucia', 'libby', 'motorbike',\n",
    "                  'paragliding', 'rhino', 'scooter-gray', 'swing']\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_attribute(contour, edge_index):\n",
    "    edge_index = edge_index.numpy()\n",
    "    edge_index = edge_index.T\n",
    "    \n",
    "    edge_attr = []\n",
    "    for edge in edge_index:\n",
    "        contour_point_0 = contour[edge[0]] \n",
    "        contour_point_1 = contour[edge[1]]\n",
    "        dist = np.linalg.norm(contour_point_0-contour_point_1)\n",
    "        edge_attr.append([dist])\n",
    "    \n",
    "    edge_atrr = np.array(edge_attr)\n",
    "    return torch.from_numpy(edge_atrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAVIS2016(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(DAVIS2016, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_file_names = ['Contours', 'Translations']\n",
    "        return raw_file_names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        raw_dir_contours = os.path.join(self.raw_dir, 'Contours')\n",
    "        copy_tree(CONTOURS_FOLDERS_PATH, raw_dir_contours)\n",
    "        \n",
    "        raw_dir_translations = os.path.join(self.raw_dir, 'Translations')\n",
    "        copy_tree(TRANSLATIONS_FOLDERS_PATH, raw_dir_translations)\n",
    "        \n",
    "    def process(self):\n",
    "        # Get paths to Contours and Translations\n",
    "        raw_path_contours, raw_path_translations = self.raw_paths\n",
    "        \n",
    "        # Get list of folders (one for each sequence)\n",
    "        translations_folders_list = os.listdir(raw_path_translations)\n",
    "        print(translations_folders_list)\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        # Iterate through folders \n",
    "        for i, folder in enumerate(translations_folders_list):\n",
    "            \n",
    "            # Skip if it is a bad sequences\n",
    "            if (folder in SKIP_SEQUENCES): continue\n",
    "            \n",
    "            # Debug\n",
    "            # if (i > 2): break\n",
    "            \n",
    "            print('#{}: {}'.format(i, folder))\n",
    "            \n",
    "            # Get paths to current sequence in Contours and Translations folders\n",
    "            contours_folder_path = os.path.join(raw_path_contours, folder)\n",
    "            translations_folder_path = os.path.join(raw_path_translations, folder)\n",
    "            \n",
    "            # Get list of translations (one for each frame in the sequence)\n",
    "            translations = os.listdir(translations_folder_path)\n",
    "            translations.sort()\n",
    "            \n",
    "            # Iterate through translations\n",
    "            for j, translation in enumerate(translations):\n",
    "                \n",
    "                # if (j > 4): break\n",
    "                \n",
    "                # print('\\t#{}: {}'.format(j, translation))\n",
    "                \n",
    "                # Load corresponding contour\n",
    "                \n",
    "                contour_path = os.path.join(contours_folder_path, translation)\n",
    "                contour = np.load(contour_path)\n",
    "                \n",
    "                # Load corresponding sequence\n",
    "                translation_path = os.path.join(translations_folder_path, translation)\n",
    "                translation = np.load(translation_path)\n",
    "                \n",
    "                # Create Data\n",
    "                \n",
    "                # x\n",
    "                # Node feature matrix with shape [num_nodes, num_node_features]\n",
    "                # The feature of each node is the OSVOS feature vector of the next frame\n",
    "                # x = get_OSVOS_feature_vectors(contour)\n",
    "                x = None\n",
    "                \n",
    "                # edge_index\n",
    "                # Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "                # Each node should be connected to its k nearest neighbours\n",
    "                positions = torch.from_numpy(contour)\n",
    "                edge_index = knn_graph(positions, K)\n",
    "                edge_index = to_undirected(edge_index)\n",
    "                # print(type(edge_index))\n",
    "                \n",
    "                # edge_attr\n",
    "                # Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "                # The feature of each edge is the distance between the two nodes it connects\n",
    "                edge_attr = get_edge_attribute(contour, edge_index)\n",
    "                # print(type(edge_attr))\n",
    "                \n",
    "                # y\n",
    "                # Target to train against (may have arbitrary shape)\n",
    "                # The target of each node is the displacement of the node between the current and the next frame\n",
    "                y = torch.from_numpy(translation)\n",
    "                # print(y)\n",
    "                \n",
    "                # Create data\n",
    "                data = Data(x=x, edge_index=edge_index, \n",
    "                            edge_attr=edge_attr, y=y)\n",
    "                data_list.append(data)\n",
    "                \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DAVIS2016(root='DAVIS2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
