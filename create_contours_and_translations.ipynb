{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Contours and Translations for DAVIS 2016 Dataset\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import src.config as cfg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf DAVIS_2016/DAVIS/Contours\n",
    "! rm -rf DAVIS_2016/DAVIS/Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gray_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_image(image, closing_kernel_size):\n",
    "    '''Returns the image that is closed with a elliptical kernel.'''\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(closing_kernel_size, closing_kernel_size))\n",
    "    closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_longest_contour(image, closing_kernel_size, method):\n",
    "    '''Returns the contour with the most points from a given image.'''\n",
    "    \n",
    "    # Close image\n",
    "    image_closed = close_image(image, closing_kernel_size)\n",
    "    \n",
    "    # Apply threshold to turn it into binary image\n",
    "    ret, thresh = cv2.threshold(image_closed, 127, 255, 0)\n",
    "\n",
    "    # Find contour\n",
    "    # Change method for different number of points:\n",
    "    # CHAIN_APPROX_NONE, CHAIN_APPROX_SIMPLE, CHAIN_APPROX_TC89_L1, CHAIN_APPROX_TC89_KCOS\n",
    "    contours, _ = cv2.findContours(image=thresh,\n",
    "                                   mode=cv2.RETR_TREE,\n",
    "                                   method=method)\n",
    "    \n",
    "    # Get longest contour from contours\n",
    "    longest_contour = max(contours, key=len).astype(np.float32)\n",
    "    \n",
    "    return longest_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_translations(contour_0, contour_1):\n",
    "    '''Returns the translations for each point in contour_0 to contour_1.'''\n",
    "    \n",
    "    contour_0 = np.squeeze(contour_0)\n",
    "    contour_1 = np.squeeze(contour_1)\n",
    "    \n",
    "    translations = contour_1 - contour_0\n",
    "    \n",
    "    translations_normalized = normalize(translations)\n",
    "\n",
    "    return translations_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annotation_with_contour_and_translation(annotation, contour, translation, path):\n",
    "    '''Saves annotation plotted with contour and translation to a given path.'''\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # Plot contour\n",
    "    contour = np.squeeze(contour)\n",
    "    plt.scatter(contour[:, 0], contour[:, 1])\n",
    "    \n",
    "    # Plot annotation\n",
    "    plt.imshow(annotation)\n",
    "    \n",
    "    # Plot translation\n",
    "    for c, t in zip(contour, translation):\n",
    "        plt.arrow(c[0], c[1],\n",
    "                  t[0], t[1],\n",
    "                  width=1, color='r')  \n",
    "    \n",
    "    # Save image\n",
    "    plt.savefig(path, bbox_inches=0)    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(contour_point_1, contour_1_real):\n",
    "    contour_1_real = np.squeeze(contour_1_real, axis=1)\n",
    "    dist = cdist(contour_point_1, contour_1_real, metric='euclidean')\n",
    "    arg_contour_point_1_final = np.argmin(dist)\n",
    "    contour_point_1_final = contour_1_real[arg_contour_point_1_final]\n",
    "    #print('contour_point_1:', contour_point_1, '--> contour_point_1_final:', contour_point_1_final)\n",
    "    return contour_point_1_final\n",
    "    \n",
    "def match_points(contour_1, contour_1_real):\n",
    "    '''Match points based on minimal distance. 2 points can be matched to the same point if it is the closest'''\n",
    "    rows_1, _, _ = contour_1.shape\n",
    "    contour_1_final = np.zeros((rows_1, 2))\n",
    "    for x in range(rows_1):\n",
    "        contour_1_final[x] = find_closest(contour_1[x], contour_1_real)\n",
    "    return contour_1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contours_and_translations(annotations_folders_path,\n",
    "                                     contours_folders_path,\n",
    "                                     translations_folders_path,\n",
    "                                     closing_kernel_size):\n",
    "\n",
    "    # Get list of sequences\n",
    "    sequences = os.listdir(annotations_folders_path)\n",
    "    sequences.sort()\n",
    "    \n",
    "    # Iterate through sequences\n",
    "    for i, sequence in enumerate(sequences):\n",
    "\n",
    "        # Debug\n",
    "        #if (i > 6): break\n",
    "        print('#{}: {}'.format(i, sequence))\n",
    "        \n",
    "        if sequence not in cfg.TRAIN_SEQUENCES:\n",
    "            augmentation_count = 1\n",
    "        else:\n",
    "            augmentation_count = cfg.AUGMENTATION_COUNT\n",
    "                                             \n",
    "        # Iterate through augmentations:\n",
    "        for j in range(augmentation_count):\n",
    "            \n",
    "            j = str(j)\n",
    "            \n",
    "            print('\\t{} #{}'.format('Augmentation', j))\n",
    "        \n",
    "            # Create folder to save Contours\n",
    "            contours_folder_path = os.path.join(contours_folders_path, sequence, j)\n",
    "            if not os.path.exists(contours_folder_path):\n",
    "                os.makedirs(contours_folder_path)        \n",
    "\n",
    "            # Create folder to save Translations\n",
    "            translations_folder_path = os.path.join(translations_folders_path, sequence, j)\n",
    "            if not os.path.exists(translations_folder_path):\n",
    "                os.makedirs(translations_folder_path)\n",
    "\n",
    "            # Get list of frames\n",
    "            frames = os.listdir(os.path.join(annotations_folders_path, sequence, j))\n",
    "            if '.ipynb_checkpoints' in frames:\n",
    "                frames.remove('.ipynb_checkpoints')\n",
    "            frames.sort()\n",
    "        \n",
    "            # Iterate through frames\n",
    "            for k, frame in enumerate(frames):\n",
    "\n",
    "                # Debug\n",
    "                #if (k > 2): break\n",
    "                #print('\\t\\t#{}: {}'.format(k, frame))\n",
    "\n",
    "                if (sequence == 'bmx-bumps' and frame == '00059.png'): break\n",
    "                if (sequence == 'surf' and frame == '00053.png'): break\n",
    "\n",
    "                # Get path to frames\n",
    "                frame_0_path = os.path.join(annotations_folders_path, sequence, j, frame)\n",
    "                try:\n",
    "                    frame_1_path = os.path.join(annotations_folders_path, sequence, j, frames[k+1])\n",
    "                # Break if frame_0 is last frame\n",
    "                except IndexError as e:\n",
    "                    break\n",
    "\n",
    "                # Load frames as gray img\n",
    "                frame_0_gray = load_gray_img(frame_0_path)\n",
    "                frame_1_gray = load_gray_img(frame_1_path)\n",
    "\n",
    "                # Extract longest contour and save it\n",
    "                contour_0 = extract_longest_contour(frame_0_gray, closing_kernel_size, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "                np.save(os.path.join(contours_folder_path, frame[:5]), contour_0)\n",
    "\n",
    "                # Calculate optical flow to get contour_1\n",
    "                contour_1, st, err = cv2.calcOpticalFlowPyrLK(frame_0_gray, frame_1_gray, \n",
    "                                                              contour_0, None, **lk_params)\n",
    "\n",
    "                translation_0_1_normalized = get_normalized_translations(contour_0, contour_1)\n",
    "\n",
    "                # Update contour_1 with normalized translations\n",
    "                contour_1 = np.add(np.squeeze(contour_0), translation_0_1_normalized)\n",
    "                contour_1 = np.expand_dims(contour_1, axis=1)\n",
    "\n",
    "                contour_1_real = extract_longest_contour(frame_1_gray, closing_kernel_size, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "                # Match contour 1 on contour 1 real\n",
    "                contour_1_final = match_points(contour_1, contour_1_real)\n",
    "\n",
    "                # Get translation and save it\n",
    "                translation_0_1_final = contour_1_final - np.squeeze(contour_0)\n",
    "\n",
    "                correction = np.mean(np.linalg.norm(translation_0_1_normalized-translation_0_1_final, axis=1))\n",
    "                #print('\\t-> Mean correction after projecting on real contour:', np.mean(translation_0_1-translation_0_1_final))\n",
    "\n",
    "                np.save(os.path.join(translations_folder_path, frame[:5]), translation_0_1_final)\n",
    "\n",
    "                # Save annotation with contour and translation\n",
    "                annotation = cv2.imread(os.path.join(annotations_folders_path, sequence, j, frame))\n",
    "                save_annotation_with_contour_and_translation(annotation, contour_0, translation_0_1_final, \n",
    "                    os.path.join(translations_folder_path, frame[:5] + '.png'))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Contours and Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: bear\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#1: blackswan\n",
      "\tAugmentation #0\n",
      "#2: bmx-bumps\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#3: bmx-trees\n",
      "\tAugmentation #0\n",
      "#4: boat\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#5: breakdance\n",
      "\tAugmentation #0\n",
      "#6: breakdance-flare\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#7: bus\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#8: camel\n",
      "\tAugmentation #0\n",
      "#9: car-roundabout\n",
      "\tAugmentation #0\n",
      "#10: car-shadow\n",
      "\tAugmentation #0\n",
      "#11: car-turn\n",
      "\tAugmentation #0\n",
      "\tAugmentation #1\n",
      "\tAugmentation #2\n",
      "#12: cows\n",
      "\tAugmentation #0\n"
     ]
    }
   ],
   "source": [
    "create_contours_and_translations(cfg.ANNOTATIONS_AUGMENTED_FOLDERS_PATH,\n",
    "                                 cfg.CONTOURS_FOLDERS_PATH,\n",
    "                                 cfg.TRANSLATIONS_FOLDERS_PATH,\n",
    "                                 cfg.CLOSING_KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
