{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_networks.gcn import GCN\n",
    "import src.config as cfg\n",
    "from src.davis_2016 import DAVIS2016\n",
    "from src.metrics import db_eval_iou, db_eval_boundary, db_eval_t_stab\n",
    "from src.vis_utils import compute_combo_img\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '15057.182069204_best_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DAVIS2016(cfg.PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                cfg.CONTOURS_FOLDERS_PATH, cfg.IMAGES_AUGMENTED_FOLDERS_PATH, cfg.TRANSLATIONS_FOLDERS_PATH, \n",
    "                cfg.LAYER, cfg.K, cfg.EPOCHS_WO_AVEGRAD, 1,\n",
    "                cfg.SKIP_SEQUENCES, cfg.TRAIN_SEQUENCES[:], cfg.VAL_SEQUENCES[15:],\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val size: 357\n"
     ]
    }
   ],
   "source": [
    "print(\"Val size: %i\" % len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(256, 512)\n",
       "  (conv2): GCNConv(512, 512)\n",
       "  (conv3): GCNConv(512, 1024)\n",
       "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (lin2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lin3): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(in_channels=val[0].num_features, out_channels=val[0].y.shape[1])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motocross-jump\n",
      "\tmean_J_combo: 0.6125047943802047, mean_J_osvos: 0.6503471016028604\n",
      "\tmean_F_combo: 0.5384077503995768, mean_F_osvos: 0.5875214975023312\n",
      "paragliding-launch\n",
      "\tmean_J_combo: 0.6099725472024609, mean_J_osvos: 0.6174057789598415\n",
      "\tmean_F_combo: 0.5956510269013316, mean_F_osvos: 0.6027452645867117\n",
      "parkour\n",
      "\tmean_J_combo: 0.806116636962922, mean_J_osvos: 0.8794923903394034\n",
      "\tmean_F_combo: 0.8340619633277734, mean_F_osvos: 0.8688266479644037\n",
      "scooter-black\n",
      "\tmean_J_combo: 0.5015314384957784, mean_J_osvos: 0.5377931169400938\n",
      "\tmean_F_combo: 0.6366506172199692, mean_F_osvos: 0.6685280987377937\n",
      "soapbox\n",
      "\tmean_J_combo: 0.8372865636175877, mean_J_osvos: 0.8580771285333614\n",
      "\tmean_F_combo: 0.8127218475511981, mean_F_osvos: 0.8259189933398496\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val, batch_size=1, shuffle=False, sampler=SequentialSampler(val))\n",
    "file_names = val.processed_file_names\n",
    "\n",
    "for i, data in enumerate(val_loader):\n",
    "    \n",
    "    #if i > 0: break\n",
    "    \n",
    "    # Forward pass to get outputs\n",
    "    with torch.no_grad():\n",
    "        translation_0_1_pred = model(data)\n",
    "        \n",
    "    # Get folder and filename for images\n",
    "    try:\n",
    "        file_name_1 = file_names[i + 1]    \n",
    "    # Break if file_name_1 is last frame\n",
    "    except IndexError as e:\n",
    "        mean_J_combo = running_J_combo / running_index\n",
    "        mean_J_osvos = running_J_osvos / running_index\n",
    "        mean_F_combo = running_F_combo / running_index\n",
    "        mean_F_osvos = running_F_osvos / running_index\n",
    "        \n",
    "        print(folder_old)\n",
    "        print('\\tmean_J_combo: {}, mean_J_osvos: {}'.format(mean_J_combo, mean_J_osvos))\n",
    "        print('\\tmean_F_combo: {}, mean_F_osvos: {}'.format(mean_F_combo, mean_F_osvos))\n",
    "        break\n",
    "        \n",
    "    folder_1 = file_name_1[:-11]\n",
    "    augmentation_count_1 = file_name_1[-10:-9]\n",
    "    file_name_1 = file_name_1[-8:-3]\n",
    "    \n",
    "    # Load OSVOS result image\n",
    "    osvos_img_1_path = os.path.join(cfg.OSVOS_RESULTS_FOLDERS_PATH, folder_1,\n",
    "                                    ('{}{}'.format(file_name_1, '.png')))\n",
    "    osvos_img_1 = cv2.imread(osvos_img_1_path)\n",
    "    osvos_img_1_gray = cv2.imread(osvos_img_1_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Load ground truth annotation\n",
    "    annotation_img_1_path = os.path.join(cfg.ANNOTATIONS_AUGMENTED_FOLDERS_PATH, folder_1, augmentation_count_1,\n",
    "                                         ('{}{}'.format(file_name_1, '.png')))\n",
    "    annotation_img_1 = cv2.imread(annotation_img_1_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Get contour\n",
    "    contour_0 = data.contour\n",
    "    contour_1_pred = contour_0.type(torch.DoubleTensor).add(translation_0_1_pred)\n",
    "    \n",
    "    # Create combined image\n",
    "    _, combo_img_1, _, _ = compute_combo_img(contour_1_pred, osvos_img_1)\n",
    "    combo_img_1_path = os.path.join(cfg.COMBO_RESULTS_FOLDERS_PATH, folder_1, \n",
    "                                    ('{}{}'.format(file_name_1, '.png')))\n",
    "    \n",
    "    if not os.path.exists(os.path.join(cfg.COMBO_RESULTS_FOLDERS_PATH, folder_1)):\n",
    "        os.makedirs(os.path.join(cfg.COMBO_RESULTS_FOLDERS_PATH, folder_1))\n",
    "        \n",
    "    cv2.imwrite(combo_img_1_path, combo_img_1*255)\n",
    "    \n",
    "    #Compute J\n",
    "    J_combo = db_eval_iou(annotation_img_1, combo_img_1)\n",
    "    J_osvos = db_eval_iou(annotation_img_1, osvos_img_1_gray)\n",
    "    \n",
    "    #Compute F\n",
    "    F_combo = db_eval_boundary(combo_img_1, annotation_img_1)\n",
    "    F_osvos = db_eval_boundary(osvos_img_1_gray, annotation_img_1)\n",
    "    \n",
    "    # Compute metrics per sequence\n",
    "    if i == 0:\n",
    "        running_index = 0\n",
    "        running_J_combo = 0.\n",
    "        running_J_osvos = 0.\n",
    "        running_F_combo = 0.\n",
    "        running_F_osvos = 0.\n",
    "        folder_old = folder_1\n",
    "\n",
    "    # Update metrics if sequence is the same\n",
    "    if folder_old == folder_1:\n",
    "        running_index += 1\n",
    "        running_J_combo += J_combo\n",
    "        running_J_osvos += J_osvos\n",
    "        running_F_combo += F_combo\n",
    "        running_F_osvos += F_osvos\n",
    "    # Calculate mean, print, and reset if new sequence\n",
    "    else:\n",
    "        mean_J_combo = running_J_combo / running_index\n",
    "        mean_J_osvos = running_J_osvos / running_index\n",
    "        mean_F_combo = running_F_combo / running_index\n",
    "        mean_F_osvos = running_F_osvos / running_index\n",
    "        \n",
    "        print(folder_old)\n",
    "        print('\\tmean_J_combo: {}, mean_J_osvos: {}'.format(mean_J_combo, mean_J_osvos))\n",
    "        print('\\tmean_F_combo: {}, mean_F_osvos: {}'.format(mean_F_combo, mean_F_osvos))\n",
    "        \n",
    "        folder_old = folder_1\n",
    "        running_index = 0\n",
    "        running_J_combo = 0.\n",
    "        running_J_osvos = 0.\n",
    "        running_F_combo = 0.\n",
    "        running_F_osvos = 0.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
