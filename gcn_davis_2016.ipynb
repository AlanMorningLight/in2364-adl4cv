{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN for DAVIS 2016\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html). The dataset is then used to train a simple GCN network as a first evaluation based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#learning-methods-on-graphs).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_datasets.davis_2016 import DAVIS2016\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH = 'pg_datasets/DAVIS_2016'\n",
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "IMAGES_FOLDERS_PATH = 'DAVIS_2016/DAVIS/JPEGImages/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'\n",
    "\n",
    "SKIP_SEQUENCES = ['bmx-trees', 'bus', 'cows', 'dog-agility', 'horsejump-high', \n",
    "                  'horsejump-low', 'kite-walk', 'lucia', 'libby', 'motorbike',\n",
    "                  'paragliding', 'rhino', 'scooter-gray', 'swing']\n",
    "\n",
    "UNEQUAL_TRANSLATION_LENGTH = ['surf', 'bmx-bumps']\n",
    "\n",
    "SKIP_SEQUENCES += UNEQUAL_TRANSLATION_LENGTH\n",
    "\n",
    "TRAIN_SEQUENCES = ['bear', 'bmx-bumps', 'boat', 'breakdance-flare', 'bus', \n",
    "                   'car-turn', 'dance-jump', 'dog-agility', 'drift-turn', \n",
    "                   'elephant', 'flamingo', 'hike', 'hockey', 'horsejump-low', \n",
    "                   'kite-walk', 'lucia', 'mallard-fly', 'mallard-water', \n",
    "                   'motocross-bumps', 'motorbike', 'paragliding', 'rhino', \n",
    "                   'rollerblade', 'scooter-gray', 'soccerball', 'stroller',\n",
    "                   'surf', 'swing', 'tennis', 'train']\n",
    "\n",
    "VAL_SEQUENCES = ['blackswan', 'bmx-trees', 'breakdance', 'camel', 'car-roundabout',\n",
    "                 'car-shadow', 'cows', 'dance-twirl', 'dog', 'drift-chicane', \n",
    "                 'drift-straight', 'goat', 'horsejump-high', 'kite-surf', 'libby', \n",
    "                 'motocross-jump', 'paragliding-launch', 'parkour', 'scooter-black', \n",
    "                 'soapbox']\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LAYER = 9\n",
    "K = 32\n",
    "EPOCHS_WO_AVEGRAD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                  CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                  LAYER, K, EPOCHS_WO_AVEGRAD,\n",
    "                  SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                  train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                LAYER, K, EPOCHS_WO_AVEGRAD,\n",
    "                SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[15768], edge_index=[2, 15768], x=[256, 128], y=[256, 2])\n"
     ]
    }
   ],
   "source": [
    "data = train[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(in_channels, in_channels * 2)\n",
    "        self.conv2 = GCNConv(in_channels * 2, in_channels * 2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_channels * 2, in_channels)\n",
    "        self.lin2 = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "                \n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "def val_net(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(val_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        # forward pass to get outputs\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "\n",
    "        # calculate the loss between predicted and target keypoints\n",
    "        out_flatten = out.flatten()\n",
    "        y_flatten = data.y.flatten()\n",
    "        loss = criterion(out_flatten, y_flatten)\n",
    "\n",
    "        # log the loss every log_nth iterations\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss = running_loss/len(val_loader)\n",
    "    print(\"Loss on VAL data: {}\".format(loss))\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "def train_net(model, train_loader, val_loader, optimizer, criterion, num_epochs=10, log_nth=10, verbose=True):\n",
    "\n",
    "    # Logging into Tensorboard\n",
    "    log_dir = os.path.join('GCN_Files', 'runs', datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "    writer1 = SummaryWriter(logdir=log_dir, comment='train')\n",
    "    writer2 = SummaryWriter(logdir=log_dir, comment='val')\n",
    "    \n",
    "    # prepare the net for training\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    if verbose: print('START TRAIN.')\n",
    "        \n",
    "    start_time = timeit.default_timer()\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch::', epoch+1, '/', num_epochs)\n",
    "        running_loss = 0.0\n",
    "        # train on batches of data\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            out = model(data)\n",
    "            \n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            out_flatten = out.flatten()\n",
    "            y_flatten = data.y.flatten()\n",
    "            \n",
    "            loss = criterion(out_flatten, y_flatten)\n",
    "            print('\\tBatch:', i+1, '/', len(train_loader), ': Loss:', loss.data)\n",
    "            writer1.add_scalar('data', loss.item(), epoch)\n",
    "            # backward pass to calculate the weight gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # store loss for each batch\n",
    "            train_loss_history.append(loss.data)\n",
    "            \n",
    "            # log the loss every log_nth iterations\n",
    "            running_loss += loss.item()\n",
    "            if i % log_nth == log_nth - 1:\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.5f' \n",
    "                          %(epoch + 1, i + 1, running_loss / log_nth))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        #Compute val loss after each epoch\n",
    "        train_loss_epoch = np.mean([x.cpu().numpy() for x in train_loss_history[-i-1:]])\n",
    "        print('Loss on TRAIN data (mean):', train_loss_epoch)\n",
    "\n",
    "        val_loss = val_net(model, val_loader, criterion)\n",
    "        writer1.add_scalars('data', {'train': train_loss_epoch, 'val': val_loss}, epoch)\n",
    "        #writer2.add_scalar('data/total_loss_epoch', val_loss, epoch)\n",
    "        val_loss_history.append(val_loss)\n",
    "    if verbose: print('FINISH.')\n",
    "    \n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GCNConv(128, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (lin2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:: 1 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(964.4807, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(749.6680, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 857.0743821949195\n",
      "Loss on VAL data: 459.2409165193465\n",
      "\n",
      "Epoch:: 2 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(119.8948, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(74.2903, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 97.09254918926513\n",
      "Loss on VAL data: 338.018131624938\n",
      "\n",
      "Epoch:: 3 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(45.7826, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(29.4599, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 37.621247633654576\n",
      "Loss on VAL data: 309.7544450945732\n",
      "\n",
      "Epoch:: 4 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(19.8380, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(20.0740, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 19.955993333107635\n",
      "Loss on VAL data: 331.03574540269\n",
      "\n",
      "Epoch:: 5 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(20.8984, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(25.2923, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 23.095309955047757\n",
      "Loss on VAL data: 366.42653602663177\n",
      "\n",
      "Epoch:: 6 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(27.8675, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(29.7140, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 28.790715165700533\n",
      "Loss on VAL data: 391.34142987887117\n",
      "\n",
      "Epoch:: 7 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(29.5681, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(26.9296, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 28.248836354029248\n",
      "Loss on VAL data: 397.21638586497784\n",
      "\n",
      "Epoch:: 8 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(24.2270, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(19.3553, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 21.791128782055964\n",
      "Loss on VAL data: 386.20272204051207\n",
      "\n",
      "Epoch:: 9 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(15.3991, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(10.9060, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 13.152539198746759\n",
      "Loss on VAL data: 363.87895989248005\n",
      "\n",
      "Epoch:: 10 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(8.0294, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(5.5988, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 6.814112433064982\n",
      "Loss on VAL data: 336.94388272703003\n",
      "\n",
      "Epoch:: 11 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(5.0761, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.9269, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 5.001500397952512\n",
      "Loss on VAL data: 312.98420975743505\n",
      "\n",
      "Epoch:: 12 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(6.3798, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(7.0471, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 6.713447184951528\n",
      "Loss on VAL data: 297.07605270509725\n",
      "\n",
      "Epoch:: 13 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(9.0810, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(8.8840, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 8.982497693613375\n",
      "Loss on VAL data: 291.02461978774664\n",
      "\n",
      "Epoch:: 14 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(10.1712, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(8.7135, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 9.442304421585877\n",
      "Loss on VAL data: 293.2685270044684\n",
      "\n",
      "Epoch:: 15 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(9.0101, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(6.9413, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 7.975718093185214\n",
      "Loss on VAL data: 300.7954566662788\n",
      "\n",
      "Epoch:: 16 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(6.6928, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(5.0302, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 5.861457769799183\n",
      "Loss on VAL data: 310.02645427637964\n",
      "\n",
      "Epoch:: 17 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.6385, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.8495, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.244041469590859\n",
      "Loss on VAL data: 317.68020242157445\n",
      "\n",
      "Epoch:: 18 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6184, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.6389, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.628683372642368\n",
      "Loss on VAL data: 321.6284920840596\n",
      "\n",
      "Epoch:: 19 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5597, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.0761, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.817861518433325\n",
      "Loss on VAL data: 321.73608544678456\n",
      "\n",
      "Epoch:: 20 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.0005, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.6421, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.321288696295225\n",
      "Loss on VAL data: 319.2299239947817\n",
      "\n",
      "Epoch:: 21 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.4103, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.8705, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.640396882191846\n",
      "Loss on VAL data: 315.8263958926971\n",
      "\n",
      "Epoch:: 22 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.4315, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.5779, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.504708069847972\n",
      "Loss on VAL data: 312.90357446821184\n",
      "\n",
      "Epoch:: 23 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.0708, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.9999, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.035356159720185\n",
      "Loss on VAL data: 310.98045307679246\n",
      "\n",
      "Epoch:: 24 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6481, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5555, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.6017792611545447\n",
      "Loss on VAL data: 309.7123981657338\n",
      "\n",
      "Epoch:: 25 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4665, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4436, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4550239668311313\n",
      "Loss on VAL data: 308.4275827467447\n",
      "\n",
      "Epoch:: 26 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5435, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5289, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.536156651411535\n",
      "Loss on VAL data: 306.69804889584634\n",
      "\n",
      "Epoch:: 27 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6826, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5910, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.6368056338733132\n",
      "Loss on VAL data: 304.763441419574\n",
      "\n",
      "Epoch:: 28 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.7324, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5500, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.6411804169335857\n",
      "Loss on VAL data: 303.3894660286499\n",
      "\n",
      "Epoch:: 29 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6752, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4570, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.566125421761444\n",
      "Loss on VAL data: 303.3572066120859\n",
      "\n",
      "Epoch:: 30 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5686, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3845, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.476510547546847\n",
      "Loss on VAL data: 304.89510005100254\n",
      "\n",
      "Epoch:: 31 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4722, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3703, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.421243209564802\n",
      "Loss on VAL data: 307.4703966243123\n",
      "\n",
      "Epoch:: 32 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4233, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4135, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.418360173674478\n",
      "Loss on VAL data: 310.04275600302407\n",
      "\n",
      "Epoch:: 33 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4215, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4709, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4462289983339187\n",
      "Loss on VAL data: 311.5451876921074\n",
      "\n",
      "Epoch:: 34 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4303, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4865, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.458391723895482\n",
      "Loss on VAL data: 311.4375823455666\n",
      "\n",
      "Epoch:: 35 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4168, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4458, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4313096600211246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 309.9438955258806\n",
      "\n",
      "Epoch:: 36 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3890, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3869, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3879944403392286\n",
      "Loss on VAL data: 307.85951708994526\n",
      "\n",
      "Epoch:: 37 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3772, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3508, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3640099371626593\n",
      "Loss on VAL data: 306.0915753472611\n",
      "\n",
      "Epoch:: 38 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3912, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3435, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3673790123889393\n",
      "Loss on VAL data: 305.20820900442334\n",
      "\n",
      "Epoch:: 39 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4141, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3486, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3813159291189994\n",
      "Loss on VAL data: 305.2478659138356\n",
      "\n",
      "Epoch:: 40 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4262, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3523, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3892189670680937\n",
      "Loss on VAL data: 305.83330608469674\n",
      "\n",
      "Epoch:: 41 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4212, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3504, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.385755614177675\n",
      "Loss on VAL data: 306.4736649735321\n",
      "\n",
      "Epoch:: 42 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4037, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3456, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3746546555242354\n",
      "Loss on VAL data: 306.83580904574274\n",
      "\n",
      "Epoch:: 43 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3843, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3447, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3645273771309396\n",
      "Loss on VAL data: 306.84125879582297\n",
      "\n",
      "Epoch:: 44 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3716, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3507, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3611863596247464\n",
      "Loss on VAL data: 306.63212094298234\n",
      "\n",
      "Epoch:: 45 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3673, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3580, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3626285914226357\n",
      "Loss on VAL data: 306.4256571482128\n",
      "\n",
      "Epoch:: 46 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3674, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3593, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.36334403653488\n",
      "Loss on VAL data: 306.33127917531823\n",
      "\n",
      "Epoch:: 47 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3668, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3542, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3605215578362206\n",
      "Loss on VAL data: 306.211431731653\n",
      "\n",
      "Epoch:: 48 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3664, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3471, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3567634307033476\n",
      "Loss on VAL data: 305.91613061511606\n",
      "\n",
      "Epoch:: 49 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3685, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3410, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.354765747169332\n",
      "Loss on VAL data: 305.41989936550743\n",
      "\n",
      "Epoch:: 50 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3727, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3367, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.354722570871803\n",
      "Loss on VAL data: 304.86731564719906\n",
      "\n",
      "Epoch:: 51 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3766, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3345, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.355549081282791\n",
      "Loss on VAL data: 304.4803080894486\n",
      "\n",
      "Epoch:: 52 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3778, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3340, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.355905835172505\n",
      "Loss on VAL data: 304.4065902348977\n",
      "\n",
      "Epoch:: 53 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3753, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3350, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3551467434462823\n",
      "Loss on VAL data: 304.6239123198925\n",
      "\n",
      "Epoch:: 54 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3706, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3373, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.353956824207688\n",
      "Loss on VAL data: 304.962690670114\n",
      "\n",
      "Epoch:: 55 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3661, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3403, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3532212595257356\n",
      "Loss on VAL data: 305.22033345858233\n",
      "\n",
      "Epoch:: 56 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3633, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3422, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3527784545581274\n",
      "Loss on VAL data: 305.28351655501757\n",
      "\n",
      "Epoch:: 57 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3622, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3419, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.352043423063575\n",
      "Loss on VAL data: 305.1768034952582\n",
      "\n",
      "Epoch:: 58 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3623, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3397, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3510093054927994\n",
      "Loss on VAL data: 305.018963821814\n",
      "\n",
      "Epoch:: 59 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3632, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3369, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3500596849228605\n",
      "Loss on VAL data: 304.9250155516443\n",
      "\n",
      "Epoch:: 60 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3646, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3343, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.349453357495336\n",
      "Loss on VAL data: 304.93339765415243\n",
      "\n",
      "Epoch:: 61 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3658, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3326, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.349190482878013\n",
      "Loss on VAL data: 305.0089118828014\n",
      "\n",
      "Epoch:: 62 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3664, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3317, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.349044528471641\n",
      "Loss on VAL data: 305.09374800975206\n",
      "\n",
      "Epoch:: 63 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3661, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3313, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.348735563597821\n",
      "Loss on VAL data: 305.1585567292182\n",
      "\n",
      "Epoch:: 64 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3650, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3315, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3482479982474693\n",
      "Loss on VAL data: 305.2050236386339\n",
      "\n",
      "Epoch:: 65 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3635, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3320, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.347737871057568\n",
      "Loss on VAL data: 305.25493923387586\n",
      "\n",
      "Epoch:: 66 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3620, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3325, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3472355831541742\n",
      "Loss on VAL data: 305.3183339872101\n",
      "\n",
      "Epoch:: 67 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3607, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3327, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.346696017568743\n",
      "Loss on VAL data: 305.36674351762116\n",
      "\n",
      "Epoch:: 68 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3599, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3323, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3460987442128314\n",
      "Loss on VAL data: 305.3616946994836\n",
      "\n",
      "Epoch:: 69 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3596, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3314, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3454831146135557\n",
      "Loss on VAL data: 305.29276930482825\n",
      "\n",
      "Epoch:: 70 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3597, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3302, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.344917206898778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 305.1868862547022\n",
      "\n",
      "Epoch:: 71 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3598, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3291, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3444483232229754\n",
      "Loss on VAL data: 305.09086032572606\n",
      "\n",
      "Epoch:: 72 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3599, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3282, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3440479319650356\n",
      "Loss on VAL data: 305.0382630935333\n",
      "\n",
      "Epoch:: 73 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3597, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3276, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.343647829803241\n",
      "Loss on VAL data: 305.0283060927862\n",
      "\n",
      "Epoch:: 74 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3591, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3273, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3432037084276356\n",
      "Loss on VAL data: 305.0343307528587\n",
      "\n",
      "Epoch:: 75 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3584, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3271, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3427277049635693\n",
      "Loss on VAL data: 305.0348356834293\n",
      "\n",
      "Epoch:: 76 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3576, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3269, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3422302504994246\n",
      "Loss on VAL data: 305.02728177908267\n",
      "\n",
      "Epoch:: 77 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3569, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3265, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3417039219927474\n",
      "Loss on VAL data: 305.0207862750581\n",
      "\n",
      "Epoch:: 78 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3564, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3260, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.341163016092259\n",
      "Loss on VAL data: 305.0207111543526\n",
      "\n",
      "Epoch:: 79 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3560, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3253, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3406282387396065\n",
      "Loss on VAL data: 305.021977549065\n",
      "\n",
      "Epoch:: 80 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3557, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3246, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3401126818793947\n",
      "Loss on VAL data: 305.0165077152002\n",
      "\n",
      "Epoch:: 81 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3554, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3239, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.33962133407688\n",
      "Loss on VAL data: 305.0014114563984\n",
      "\n",
      "Epoch:: 82 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3550, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3233, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3391430567999505\n",
      "Loss on VAL data: 304.97825659742983\n",
      "\n",
      "Epoch:: 83 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3546, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3228, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.338669385945536\n",
      "Loss on VAL data: 304.9569481456651\n",
      "\n",
      "Epoch:: 84 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3541, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3223, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3381939941606014\n",
      "Loss on VAL data: 304.9505426985116\n",
      "\n",
      "Epoch:: 85 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3535, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3219, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.337707196784961\n",
      "Loss on VAL data: 304.96042330343374\n",
      "\n",
      "Epoch:: 86 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3529, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3215, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.337210808422361\n",
      "Loss on VAL data: 304.97017703045185\n",
      "\n",
      "Epoch:: 87 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3524, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3211, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.336709425651595\n",
      "Loss on VAL data: 304.96046918101\n",
      "\n",
      "Epoch:: 88 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3519, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3205, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3362071303953598\n",
      "Loss on VAL data: 304.9283164318216\n",
      "\n",
      "Epoch:: 89 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3515, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3199, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3357049315392056\n",
      "Loss on VAL data: 304.8874589678327\n",
      "\n",
      "Epoch:: 90 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3512, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3193, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3352281397829735\n",
      "Loss on VAL data: 304.79546395890264\n",
      "\n",
      "Epoch:: 91 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3508, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3186, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.334724796291729\n",
      "Loss on VAL data: 304.73004483511835\n",
      "\n",
      "Epoch:: 92 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3504, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3180, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3342255781290246\n",
      "Loss on VAL data: 304.68334313891916\n",
      "\n",
      "Epoch:: 93 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3500, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3174, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.333704759820626\n",
      "Loss on VAL data: 304.6388920821824\n",
      "\n",
      "Epoch:: 94 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3495, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3168, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.333156617082328\n",
      "Loss on VAL data: 304.5883128481948\n",
      "\n",
      "Epoch:: 95 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3491, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3161, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3325854152677783\n",
      "Loss on VAL data: 304.52180183781337\n",
      "\n",
      "Epoch:: 96 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3486, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3156, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.332125638821087\n",
      "Loss on VAL data: 304.4066713283248\n",
      "\n",
      "Epoch:: 97 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3482, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3152, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3317130611000523\n",
      "Loss on VAL data: 304.32395688629543\n",
      "\n",
      "Epoch:: 98 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3478, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3147, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.331264439371222\n",
      "Loss on VAL data: 304.2631081620793\n",
      "\n",
      "Epoch:: 99 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3474, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3142, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3307649564807202\n",
      "Loss on VAL data: 304.2081988472732\n",
      "\n",
      "Epoch:: 100 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3470, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3135, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3302444376045033\n",
      "Loss on VAL data: 304.15218862053734\n",
      "\n",
      "Epoch:: 101 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3465, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3130, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.329756065434803\n",
      "Loss on VAL data: 304.10129701093575\n",
      "\n",
      "Epoch:: 102 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3461, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3126, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.329306283919233\n",
      "Loss on VAL data: 304.063459429123\n",
      "\n",
      "Epoch:: 103 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3456, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3121, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.328850555800253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 304.037800560025\n",
      "\n",
      "Epoch:: 104 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3451, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3117, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.328362758938292\n",
      "Loss on VAL data: 304.01534220517806\n",
      "\n",
      "Epoch:: 105 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3446, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3111, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3278621128463435\n",
      "Loss on VAL data: 303.9888237504005\n",
      "\n",
      "Epoch:: 106 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3442, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3106, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.327395396490904\n",
      "Loss on VAL data: 303.9570549338635\n",
      "\n",
      "Epoch:: 107 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3437, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3101, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3269239503120027\n",
      "Loss on VAL data: 303.92796413238796\n",
      "\n",
      "Epoch:: 108 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3435, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3096, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3265236303340453\n",
      "Loss on VAL data: 303.798106226043\n",
      "\n",
      "Epoch:: 109 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3429, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3091, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.326012121156401\n",
      "Loss on VAL data: 303.70467234209065\n",
      "\n",
      "Epoch:: 110 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3425, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3086, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.325573490698445\n",
      "Loss on VAL data: 303.6368753323543\n",
      "\n",
      "Epoch:: 111 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3420, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3082, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3251206943455065\n",
      "Loss on VAL data: 303.578508729898\n",
      "\n",
      "Epoch:: 112 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3416, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3077, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3246576682662807\n",
      "Loss on VAL data: 303.52629400759514\n",
      "\n",
      "Epoch:: 113 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3412, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3072, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.324200755211085\n",
      "Loss on VAL data: 303.47946493648794\n",
      "\n",
      "Epoch:: 114 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3407, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3068, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3237387481128406\n",
      "Loss on VAL data: 303.43902388827246\n",
      "\n",
      "Epoch:: 115 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3403, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3063, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3232752818436166\n",
      "Loss on VAL data: 303.4066220838714\n",
      "\n",
      "Epoch:: 116 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3399, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3058, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3228159901117564\n",
      "Loss on VAL data: 303.378473514654\n",
      "\n",
      "Epoch:: 117 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3394, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3053, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.322357009510547\n",
      "Loss on VAL data: 303.35144966790523\n",
      "\n",
      "Epoch:: 118 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3390, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3048, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3218952591141484\n",
      "Loss on VAL data: 303.3300354315919\n",
      "\n",
      "Epoch:: 119 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3386, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3043, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.32148297694785\n",
      "Loss on VAL data: 303.2172556297645\n",
      "\n",
      "Epoch:: 120 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3381, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3039, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.321008665310084\n",
      "Loss on VAL data: 303.13256941092754\n",
      "\n",
      "Epoch:: 121 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3377, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3035, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3205713736062767\n",
      "Loss on VAL data: 303.0665231591044\n",
      "\n",
      "Epoch:: 122 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3373, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3030, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3201280194807827\n",
      "Loss on VAL data: 303.00812200230575\n",
      "\n",
      "Epoch:: 123 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3368, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3025, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3196812415439036\n",
      "Loss on VAL data: 302.95462060409346\n",
      "\n",
      "Epoch:: 124 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3364, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3020, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.319232563187221\n",
      "Loss on VAL data: 302.9117546309878\n",
      "\n",
      "Epoch:: 125 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3360, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3015, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3187826188288314\n",
      "Loss on VAL data: 302.88138133278426\n",
      "\n",
      "Epoch:: 126 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3356, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3011, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.318334102036908\n",
      "Loss on VAL data: 302.86166125448926\n",
      "\n",
      "Epoch:: 127 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3352, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3006, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3178916776550107\n",
      "Loss on VAL data: 302.7631066314711\n",
      "\n",
      "Epoch:: 128 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3348, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3001, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.317455883434448\n",
      "Loss on VAL data: 302.69172882165896\n",
      "\n",
      "Epoch:: 129 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3344, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2997, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.317020224634155\n",
      "Loss on VAL data: 302.63956210374675\n",
      "\n",
      "Epoch:: 130 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3339, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2992, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.316579986262909\n",
      "Loss on VAL data: 302.59708785555443\n",
      "\n",
      "Epoch:: 131 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3335, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2988, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.316135622971691\n",
      "Loss on VAL data: 302.5592544962682\n",
      "\n",
      "Epoch:: 132 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3331, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2983, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3156892831367974\n",
      "Loss on VAL data: 302.53177436099236\n",
      "\n",
      "Epoch:: 133 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3327, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2978, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3152953853704625\n",
      "Loss on VAL data: 302.4044342721429\n",
      "\n",
      "Epoch:: 134 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3323, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2974, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3148403615324904\n",
      "Loss on VAL data: 302.3188858263325\n",
      "\n",
      "Epoch:: 135 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3319, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2970, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.314424046979129\n",
      "Loss on VAL data: 302.262562858086\n",
      "\n",
      "Epoch:: 136 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3315, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2965, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3140015206545206\n",
      "Loss on VAL data: 302.2136942328894\n",
      "\n",
      "Epoch:: 137 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3311, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2961, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3135714070585047\n",
      "Loss on VAL data: 302.1668376495912\n",
      "\n",
      "Epoch:: 138 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3307, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2956, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3131408767194124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 302.1322038265573\n",
      "\n",
      "Epoch:: 139 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3303, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2951, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.312707517090969\n",
      "Loss on VAL data: 302.1165808658707\n",
      "\n",
      "Epoch:: 140 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3299, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2947, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3122713132855037\n",
      "Loss on VAL data: 302.1152023293679\n",
      "\n",
      "Epoch:: 141 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3296, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2942, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3119020901638963\n",
      "Loss on VAL data: 301.99811434871526\n",
      "\n",
      "Epoch:: 142 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3291, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2938, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3114348146113506\n",
      "Loss on VAL data: 301.9164618783984\n",
      "\n",
      "Epoch:: 143 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3287, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2934, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.311024536095365\n",
      "Loss on VAL data: 301.861362015259\n",
      "\n",
      "Epoch:: 144 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3283, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2929, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3106063671960095\n",
      "Loss on VAL data: 301.82065510266654\n",
      "\n",
      "Epoch:: 145 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3279, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2925, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.310180499153291\n",
      "Loss on VAL data: 301.7866852957299\n",
      "\n",
      "Epoch:: 146 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3275, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2921, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.309752606817477\n",
      "Loss on VAL data: 301.76422321037126\n",
      "\n",
      "Epoch:: 147 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3271, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2916, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3093437968020813\n",
      "Loss on VAL data: 301.6620732330378\n",
      "\n",
      "Epoch:: 148 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3267, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2912, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.308920520871483\n",
      "Loss on VAL data: 301.6041606132288\n",
      "\n",
      "Epoch:: 149 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3263, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2907, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.308507347030123\n",
      "Loss on VAL data: 301.568853767227\n",
      "\n",
      "Epoch:: 150 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3259, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2903, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3080824574940575\n",
      "Loss on VAL data: 301.539767991897\n",
      "\n",
      "Epoch:: 151 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3255, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2898, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3076605690927856\n",
      "Loss on VAL data: 301.46436440044107\n",
      "\n",
      "Epoch:: 152 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3251, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2894, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3072356394768\n",
      "Loss on VAL data: 301.3710264584183\n",
      "\n",
      "Epoch:: 153 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3247, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2890, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.306827799872339\n",
      "Loss on VAL data: 301.3268036836604\n",
      "\n",
      "Epoch:: 154 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3243, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2885, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.306406386933686\n",
      "Loss on VAL data: 301.30756970919714\n",
      "\n",
      "Epoch:: 155 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3239, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2881, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3059811231761045\n",
      "Loss on VAL data: 301.21338776663515\n",
      "\n",
      "Epoch:: 156 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3235, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2876, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3055724041992067\n",
      "Loss on VAL data: 301.14233153846124\n",
      "\n",
      "Epoch:: 157 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3231, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2872, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3051532844185774\n",
      "Loss on VAL data: 301.1031671737015\n",
      "\n",
      "Epoch:: 158 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3227, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2867, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3047263091695553\n",
      "Loss on VAL data: 301.06550004705514\n",
      "\n",
      "Epoch:: 159 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3224, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2863, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.30433273959027\n",
      "Loss on VAL data: 300.93440492028606\n",
      "\n",
      "Epoch:: 160 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3220, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2859, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3039213366409443\n",
      "Loss on VAL data: 300.84223674151144\n",
      "\n",
      "Epoch:: 161 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3216, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2855, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.303521741469331\n",
      "Loss on VAL data: 300.78075946877885\n",
      "\n",
      "Epoch:: 162 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3212, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2850, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.30310917474307\n",
      "Loss on VAL data: 300.74074124092886\n",
      "\n",
      "Epoch:: 163 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3208, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2846, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.302687599614902\n",
      "Loss on VAL data: 300.71370283866844\n",
      "\n",
      "Epoch:: 164 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3204, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2841, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3022563993129577\n",
      "Loss on VAL data: 300.6964982020971\n",
      "\n",
      "Epoch:: 165 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3200, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2837, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3018223504011255\n",
      "Loss on VAL data: 300.6445069163667\n",
      "\n",
      "Epoch:: 166 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3196, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2833, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.301442199425356\n",
      "Loss on VAL data: 300.4752408580697\n",
      "\n",
      "Epoch:: 167 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3192, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2828, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3010439757634433\n",
      "Loss on VAL data: 300.37113636039743\n",
      "\n",
      "Epoch:: 168 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3189, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2824, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3006633863000436\n",
      "Loss on VAL data: 300.30523456127366\n",
      "\n",
      "Epoch:: 169 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3185, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2820, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3002625549452835\n",
      "Loss on VAL data: 300.25473048919986\n",
      "\n",
      "Epoch:: 170 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3181, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2816, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.299839496945853\n",
      "Loss on VAL data: 300.21955284721963\n",
      "\n",
      "Epoch:: 171 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3177, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2811, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.299412974054021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 300.2043297549853\n",
      "\n",
      "Epoch:: 172 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3173, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2807, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.298975324847868\n",
      "Loss on VAL data: 300.2123176455935\n",
      "\n",
      "Epoch:: 173 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3168, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2802, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2985462585057213\n",
      "Loss on VAL data: 300.11006133924246\n",
      "\n",
      "Epoch:: 174 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3165, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2798, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2981400066691697\n",
      "Loss on VAL data: 300.04528208339775\n",
      "\n",
      "Epoch:: 175 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3161, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2794, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.297727787910935\n",
      "Loss on VAL data: 300.00712949388185\n",
      "\n",
      "Epoch:: 176 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3156, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2790, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2973159578080002\n",
      "Loss on VAL data: 299.8623070338546\n",
      "\n",
      "Epoch:: 177 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3153, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2786, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.296929037565131\n",
      "Loss on VAL data: 299.77760194166734\n",
      "\n",
      "Epoch:: 178 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3149, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2782, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2965330106000463\n",
      "Loss on VAL data: 299.7352358006721\n",
      "\n",
      "Epoch:: 179 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3145, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2777, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.296114457059976\n",
      "Loss on VAL data: 299.69834192344825\n",
      "\n",
      "Epoch:: 180 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3141, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2773, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2956835724588753\n",
      "Loss on VAL data: 299.66104375126224\n",
      "\n",
      "Epoch:: 181 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3137, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2769, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.295275844874949\n",
      "Loss on VAL data: 299.5250292586465\n",
      "\n",
      "Epoch:: 182 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3133, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2764, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2948692792408414\n",
      "Loss on VAL data: 299.4681753795125\n",
      "\n",
      "Epoch:: 183 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3129, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2760, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2944658558899667\n",
      "Loss on VAL data: 299.45875353020415\n",
      "\n",
      "Epoch:: 184 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3125, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2756, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2940501122650323\n",
      "Loss on VAL data: 299.3501242893539\n",
      "\n",
      "Epoch:: 185 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3121, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2752, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2936584194349607\n",
      "Loss on VAL data: 299.2671490867686\n",
      "\n",
      "Epoch:: 186 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3117, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2748, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.293247319256066\n",
      "Loss on VAL data: 299.2326561819572\n",
      "\n",
      "Epoch:: 187 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3114, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2744, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2928853677195153\n",
      "Loss on VAL data: 299.06688738993677\n",
      "\n",
      "Epoch:: 188 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3110, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2740, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2924790999725255\n",
      "Loss on VAL data: 298.97085789083644\n",
      "\n",
      "Epoch:: 189 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3107, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2736, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2921032253054516\n",
      "Loss on VAL data: 298.9097611813395\n",
      "\n",
      "Epoch:: 190 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3103, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2731, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.29170518331597\n",
      "Loss on VAL data: 298.86041926359735\n",
      "\n",
      "Epoch:: 191 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3098, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2727, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2912858389067834\n",
      "Loss on VAL data: 298.83080754600115\n",
      "\n",
      "Epoch:: 192 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3094, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2723, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.290856305929288\n",
      "Loss on VAL data: 298.83886666888696\n",
      "\n",
      "Epoch:: 193 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3093, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2719, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2906058378730254\n",
      "Loss on VAL data: 298.5702981939412\n",
      "\n",
      "Epoch:: 194 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3087, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2715, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.290130591416048\n",
      "Loss on VAL data: 298.4074071643251\n",
      "\n",
      "Epoch:: 195 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3085, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2711, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2898175898739073\n",
      "Loss on VAL data: 298.3252239569454\n",
      "\n",
      "Epoch:: 196 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3082, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2707, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2894595054545217\n",
      "Loss on VAL data: 298.277154572017\n",
      "\n",
      "Epoch:: 197 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3078, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2703, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2890445986347254\n",
      "Loss on VAL data: 298.2563866698935\n",
      "\n",
      "Epoch:: 198 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3073, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2699, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.28860230668864\n",
      "Loss on VAL data: 298.2756214762588\n",
      "\n",
      "Epoch:: 199 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3068, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2695, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2881594964629715\n",
      "Loss on VAL data: 298.3228445649306\n",
      "\n",
      "Epoch:: 200 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3064, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2691, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2877248535983177\n",
      "Loss on VAL data: 298.2220844274687\n",
      "\n",
      "Epoch:: 201 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3060, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2687, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.287335916419831\n",
      "Loss on VAL data: 298.164049147689\n",
      "\n",
      "Epoch:: 202 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3056, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2683, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.286968586235134\n",
      "Loss on VAL data: 297.99676257221546\n",
      "\n",
      "Epoch:: 203 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3053, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2679, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2866036290061884\n",
      "Loss on VAL data: 297.90215420439654\n",
      "\n",
      "Epoch:: 204 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3049, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2676, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.286234942525809\n",
      "Loss on VAL data: 297.8540413991315\n",
      "\n",
      "Epoch:: 205 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3045, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2672, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2858342477994507\n",
      "Loss on VAL data: 297.82461646844473\n",
      "\n",
      "Epoch:: 206 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3041, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2668, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.285410432813751\n",
      "Loss on VAL data: 297.8128831163071\n",
      "\n",
      "Epoch:: 207 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3041, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 2 / 2 : Loss: tensor(3.2663, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2852085715071295\n",
      "Loss on VAL data: 297.45846132316996\n",
      "\n",
      "Epoch:: 208 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3036, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2660, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.284757992979396\n",
      "Loss on VAL data: 297.27029797477746\n",
      "\n",
      "Epoch:: 209 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3034, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2656, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.284510586353277\n",
      "Loss on VAL data: 297.1891659360512\n",
      "\n",
      "Epoch:: 210 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3031, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2652, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2841819387073006\n",
      "Loss on VAL data: 297.1276914192652\n",
      "\n",
      "Epoch:: 211 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3027, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2648, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2837719453909644\n",
      "Loss on VAL data: 297.08943136986994\n",
      "\n",
      "Epoch:: 212 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3022, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2644, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.283330406821391\n",
      "Loss on VAL data: 297.12893288383844\n",
      "\n",
      "Epoch:: 213 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3017, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2640, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.282863899532671\n",
      "Loss on VAL data: 297.21651469572197\n",
      "\n",
      "Epoch:: 214 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3012, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2636, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.282404362920909\n",
      "Loss on VAL data: 297.2925418904879\n",
      "\n",
      "Epoch:: 215 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3018, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2632, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.282501406636522\n",
      "Loss on VAL data: 296.9365048353123\n",
      "\n",
      "Epoch:: 216 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3005, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2629, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.28170953024934\n",
      "Loss on VAL data: 296.73812437413534\n",
      "\n",
      "Epoch:: 217 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3003, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2626, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.281438764257511\n",
      "Loss on VAL data: 296.6678592028966\n",
      "\n",
      "Epoch:: 218 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3000, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2622, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2811099529019323\n",
      "Loss on VAL data: 296.61721626139797\n",
      "\n",
      "Epoch:: 219 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2996, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2618, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2807015961745845\n",
      "Loss on VAL data: 296.5630861704727\n",
      "\n",
      "Epoch:: 220 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2991, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2614, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.28026915658328\n",
      "Loss on VAL data: 296.56350738881\n",
      "\n",
      "Epoch:: 221 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2987, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2610, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.279841482087631\n",
      "Loss on VAL data: 296.6296199900141\n",
      "\n",
      "Epoch:: 222 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2986, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2606, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.279589758506805\n",
      "Loss on VAL data: 296.3590452583018\n",
      "\n",
      "Epoch:: 223 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2980, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2602, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.27914127481301\n",
      "Loss on VAL data: 296.1772886823489\n",
      "\n",
      "Epoch:: 224 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2978, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2599, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2788561672856122\n",
      "Loss on VAL data: 296.0752423208266\n",
      "\n",
      "Epoch:: 225 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2975, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2596, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.278515964268628\n",
      "Loss on VAL data: 296.03329859761254\n",
      "\n",
      "Epoch:: 226 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2970, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2592, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2781071280815377\n",
      "Loss on VAL data: 296.02878814289755\n",
      "\n",
      "Epoch:: 227 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2965, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2588, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2776703775194655\n",
      "Loss on VAL data: 296.05738232598486\n",
      "\n",
      "Epoch:: 228 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2961, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2584, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2772495150564085\n",
      "Loss on VAL data: 295.9422864490792\n",
      "\n",
      "Epoch:: 229 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2957, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2580, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.276874871414938\n",
      "Loss on VAL data: 295.8563991297172\n",
      "\n",
      "Epoch:: 230 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2954, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2577, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2765192911494303\n",
      "Loss on VAL data: 295.7817053350877\n",
      "\n",
      "Epoch:: 231 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2950, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2573, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2761670331462356\n",
      "Loss on VAL data: 295.56162069980445\n",
      "\n",
      "Epoch:: 232 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2948, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2570, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2758849778173955\n",
      "Loss on VAL data: 295.44391025770875\n",
      "\n",
      "Epoch:: 233 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2944, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2567, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.275551649689929\n",
      "Loss on VAL data: 295.40101078017375\n",
      "\n",
      "Epoch:: 234 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2940, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2563, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2751662337644563\n",
      "Loss on VAL data: 295.3838583788812\n",
      "\n",
      "Epoch:: 235 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2936, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2559, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2747453619657083\n",
      "Loss on VAL data: 295.3877607136113\n",
      "\n",
      "Epoch:: 236 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2936, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2555, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2745639732083456\n",
      "Loss on VAL data: 294.98626025655136\n",
      "\n",
      "Epoch:: 237 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2932, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2552, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2741755352319784\n",
      "Loss on VAL data: 294.8042837976113\n",
      "\n",
      "Epoch:: 238 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2931, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2549, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.273981603307657\n",
      "Loss on VAL data: 294.74285640056934\n",
      "\n",
      "Epoch:: 239 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2928, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2546, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2736605817626163\n",
      "Loss on VAL data: 294.6864533309281\n",
      "\n",
      "Epoch:: 240 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2923, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 2 / 2 : Loss: tensor(3.2541, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2732274288375955\n",
      "Loss on VAL data: 294.67037070374613\n",
      "\n",
      "Epoch:: 241 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2918, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2538, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2727670301009786\n",
      "Loss on VAL data: 294.7497963684805\n",
      "\n",
      "Epoch:: 242 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2912, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2534, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2723103186832194\n",
      "Loss on VAL data: 294.87652028560603\n",
      "\n",
      "Epoch:: 243 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2918, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2530, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2724205581586863\n",
      "Loss on VAL data: 294.49714487596486\n",
      "\n",
      "Epoch:: 244 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2906, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2527, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.271660608042122\n",
      "Loss on VAL data: 294.2702891423397\n",
      "\n",
      "Epoch:: 245 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2905, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2524, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.27145447104011\n",
      "Loss on VAL data: 294.1793130659652\n",
      "\n",
      "Epoch:: 246 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2902, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2521, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2711412989869713\n",
      "Loss on VAL data: 294.1301898162415\n",
      "\n",
      "Epoch:: 247 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2897, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2517, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.270722021291019\n",
      "Loss on VAL data: 294.10227299363675\n",
      "\n",
      "Epoch:: 248 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2892, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2513, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2702806178792736\n",
      "Loss on VAL data: 294.1344457911882\n",
      "\n",
      "Epoch:: 249 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2887, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2509, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2698354882594116\n",
      "Loss on VAL data: 294.1769855161919\n",
      "\n",
      "Epoch:: 250 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2893, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2506, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.269957274832747\n",
      "Loss on VAL data: 293.73660498445344\n"
     ]
    }
   ],
   "source": [
    "num_train = 2\n",
    "OverfitSampler = SequentialSampler(range(num_train))\n",
    "\n",
    "overfit_train_loader = DataLoader(train, batch_size=1, \n",
    "                                  shuffle=False, sampler=OverfitSampler)\n",
    "overfit_val_loader = DataLoader(val, batch_size=1, shuffle=False, sampler=SequentialSampler(range(3)))\n",
    "\n",
    "\n",
    "# Load model and run the solver\n",
    "overfit_model = Net(in_channels=train[0].num_features, \n",
    "                    out_channels=train[0].y.shape[1])\n",
    "\n",
    "print(overfit_model)\n",
    "overfit_model.double()\n",
    "overfit_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(overfit_model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                       eps=1e-8, weight_decay=0.0)\n",
    "\n",
    "\n",
    "train_loss_history, val_loss_history = train_net(overfit_model, overfit_train_loader, overfit_val_loader, optimizer, criterion, \n",
    "                               num_epochs=250, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history_reduced = [i for idx, i in enumerate(train_loss_history) if idx%2==0]\n",
    "\n",
    "print(len(train_loss_history_reduced), len(val_loss_history))\n",
    "plt.plot(list(range(250)), train_loss_history_reduced, '-')\n",
    "plt.plot(list(range(250)), val_loss_history, '-')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_model.double()\n",
    "overfit_model.cpu()\n",
    "overfit_model.eval()\n",
    "\n",
    "image = cv2.imread('DAVIS_2016/DAVIS/Annotations/480p/bear/00001.png')\n",
    "sample = next(iter(overfit_train_loader))\n",
    "y = sample.y.detach().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = overfit_model(sample).detach().numpy()\n",
    "\n",
    "contour = np.load('pg_datasets/DAVIS_2016/raw/Contours/bear/00000.npy')\n",
    "\n",
    "translation_ground_truth = contour + y\n",
    "translation_pred = contour + pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_translation(image, translation_ground_truth, translation_pred):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    ax.scatter(translation_ground_truth[:, 0], translation_ground_truth[:, 1], color='g')\n",
    "    ax.scatter(translation_pred[:, 0], translation_pred[:, 1], color='r')\n",
    "    \n",
    "    # Plot image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    ax.axis('image')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_translation(image, translation_ground_truth, translation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Load model and run the solver\n",
    "model = Net(in_channels=train[0].num_features, \n",
    "            out_channels=train[0].y.shape[1])\n",
    "print(model)\n",
    "model.double()\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                       eps=1e-8, weight_decay=0.0)\n",
    "train_loss_history = train_net(model, train_loader, val_loader, optimizer, criterion,\n",
    "                               num_epochs=10, log_nth=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_net(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
