{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN for DAVIS 2016\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html). The dataset is then used to train a simple GCN network as a first evaluation based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#learning-methods-on-graphs).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_datasets.davis_2016 import DAVIS2016\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH = 'pg_datasets/DAVIS_2016'\n",
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "IMAGES_FOLDERS_PATH = 'DAVIS_2016/DAVIS/JPEGImages/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'\n",
    "\n",
    "LAYER = 9\n",
    "K = 32\n",
    "\n",
    "SKIP_SEQUENCES = ['bmx-trees', 'bus', 'cows', 'dog-agility', 'horsejump-high', \n",
    "                  'horsejump-low', 'kite-walk', 'lucia', 'libby', 'motorbike',\n",
    "                  'paragliding', 'rhino', 'scooter-gray', 'swing']\n",
    "\n",
    "TRAIN_SEQUENCES = ['bear', 'bmx-bumps', 'boat', 'breakdance-flare', 'bus', \n",
    "                   'car-turn', 'dance-jump', 'dog-agility', 'drift-turn', \n",
    "                   'elephant', 'flamingo', 'hike', 'hockey', 'horsejump-low', \n",
    "                   'kite-walk', 'lucia', 'mallard-fly', 'mallard-water', \n",
    "                   'motocross-bumps', 'motorbike', 'paragliding', 'rhino', \n",
    "                   'rollerblade', 'scooter-gray', 'soccerball', 'stroller',\n",
    "                   'surf', 'swing', 'tennis', 'train']\n",
    "\n",
    "VAL_SEQUENCES = ['blackswan', 'bmx-trees', 'breakdance', 'camel', 'car-roundabout',\n",
    "                 'car-shadow', 'cows', 'dance-twirl', 'dog', 'drift-chicane', \n",
    "                 'drift-straight', 'goat', 'horsejump-high', 'kite-surf', 'libby', \n",
    "                 'motocross-jump', 'paragliding-launch', 'parkour', 'scooter-black', \n",
    "                 'soapbox']\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                  CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                  LAYER, K, \n",
    "                  SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                  train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                LAYER, K, \n",
    "                SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr <class 'torch.Tensor'>\n",
      "edge_index <class 'torch.Tensor'>\n",
      "x <class 'torch.Tensor'>\n",
      "y <class 'torch.Tensor'>\n",
      "Data(edge_attr=[15768, 1], edge_index=[2, 15768], x=[256, 128], y=[256, 2])\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "data = train[0]\n",
    "for key, item in data:\n",
    "    print(key, type(item))\n",
    "\n",
    "print(data)\n",
    "print(data.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch(batch=[256], edge_attr=[15768, 1], edge_index=[2, 15768], x=[256, 128], y=[256, 2])\n",
      "1 Batch(batch=[256], edge_attr=[15762, 1], edge_index=[2, 15762], x=[256, 128], y=[256, 2])\n",
      "2 Batch(batch=[256], edge_attr=[15772, 1], edge_index=[2, 15772], x=[256, 128], y=[256, 2])\n",
      "3 Batch(batch=[256], edge_attr=[15754, 1], edge_index=[2, 15754], x=[256, 128], y=[256, 2])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched)\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
