{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN for DAVIS 2016\n",
    "\n",
    "In this notebook, a custom [PyTorch Geometric](https://rusty1s.github.io/pytorch_geometric/build/html/index.html) [InMemoryDataset](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/in_memory_dataset.html#InMemoryDataset) for the DAVIS 2016 dataset is created. The implementation is based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/create_dataset.html). The dataset is then used to train a simple GCN network as a first evaluation based on this [tutorial](https://rusty1s.github.io/pytorch_geometric/build/html/notes/introduction.html#learning-methods-on-graphs).\n",
    "\n",
    "The dataset consists of single PyTorch Geometric [Data](https://rusty1s.github.io/pytorch_geometric/build/html/_modules/torch_geometric/data/data.html#Data) objects which model a single graph with various attributes. For this dataset, a graph for each contour is created. Hereby, each node of the graph represents one contour point. The feature of each node is the OSVOS feature vector from the next frame at this point. Each node is connected to its K nearest neighbours. The feature of each edge is the distance between the nodes it connects. The targets of each node is the translation it undergoes from the current to the next frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from pg_datasets.davis_2016 import DAVIS2016\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH = 'pg_datasets/DAVIS_2016'\n",
    "CONTOURS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Contours/480p'\n",
    "IMAGES_FOLDERS_PATH = 'DAVIS_2016/DAVIS/JPEGImages/480p'\n",
    "TRANSLATIONS_FOLDERS_PATH = 'DAVIS_2016/DAVIS/Translations/480p'\n",
    "\n",
    "SKIP_SEQUENCES = ['bmx-trees', 'bus', 'cows', 'dog-agility', 'horsejump-high', \n",
    "                  'horsejump-low', 'kite-walk', 'lucia', 'libby', 'motorbike',\n",
    "                  'paragliding', 'rhino', 'scooter-gray', 'swing']\n",
    "\n",
    "UNEQUAL_TRANSLATION_LENGTH = ['surf', 'bmx-bumps']\n",
    "\n",
    "SKIP_SEQUENCES += UNEQUAL_TRANSLATION_LENGTH\n",
    "\n",
    "TRAIN_SEQUENCES = ['bear', 'bmx-bumps', 'boat', 'breakdance-flare', 'bus', \n",
    "                   'car-turn', 'dance-jump', 'dog-agility', 'drift-turn', \n",
    "                   'elephant', 'flamingo', 'hike', 'hockey', 'horsejump-low', \n",
    "                   'kite-walk', 'lucia', 'mallard-fly', 'mallard-water', \n",
    "                   'motocross-bumps', 'motorbike', 'paragliding', 'rhino', \n",
    "                   'rollerblade', 'scooter-gray', 'soccerball', 'stroller',\n",
    "                   'surf', 'swing', 'tennis', 'train']\n",
    "\n",
    "VAL_SEQUENCES = ['blackswan', 'bmx-trees', 'breakdance', 'camel', 'car-roundabout',\n",
    "                 'car-shadow', 'cows', 'dance-twirl', 'dog', 'drift-chicane', \n",
    "                 'drift-straight', 'goat', 'horsejump-high', 'kite-surf', 'libby', \n",
    "                 'motocross-jump', 'paragliding-launch', 'parkour', 'scooter-black', \n",
    "                 'soapbox']\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LAYER = 9\n",
    "K = 32\n",
    "EPOCHS_WO_AVEGRAD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                  CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                  LAYER, K, EPOCHS_WO_AVEGRAD,\n",
    "                  SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                  train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DAVIS2016(PYTORCH_GEOMETRIC_DAVIS_2016_DATASET_PATH, \n",
    "                CONTOURS_FOLDERS_PATH, IMAGES_FOLDERS_PATH, TRANSLATIONS_FOLDERS_PATH, \n",
    "                LAYER, K, EPOCHS_WO_AVEGRAD,\n",
    "                SKIP_SEQUENCES, TRAIN_SEQUENCES, VAL_SEQUENCES,\n",
    "                train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[15768], edge_index=[2, 15768], x=[256, 128], y=[256, 2])\n"
     ]
    }
   ],
   "source": [
    "data = train[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(in_channels, in_channels * 2)\n",
    "        self.conv2 = GCNConv(in_channels * 2, in_channels * 2)\n",
    "        \n",
    "        self.lin1 = nn.Linear(in_channels * 2, in_channels)\n",
    "        self.lin2 = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "                \n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "def val_net(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(val_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        # forward pass to get outputs\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "\n",
    "        # calculate the loss between predicted and target keypoints\n",
    "        out_flatten = out.flatten()\n",
    "        y_flatten = data.y.flatten()\n",
    "        loss = criterion(out_flatten, y_flatten)\n",
    "\n",
    "        # log the loss every log_nth iterations\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss = running_loss/len(val_loader)\n",
    "    print(\"Loss on VAL data: {}\".format(loss))\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "def train_net(model, train_loader, val_loader, optimizer, criterion, num_epochs=10, log_nth=10, verbose=True):\n",
    "\n",
    "    # Logging into Tensorboard\n",
    "    log_dir = os.path.join('GCN_Files', 'runs', datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "    writer1 = SummaryWriter(logdir=log_dir, comment='train')\n",
    "    writer2 = SummaryWriter(logdir=log_dir, comment='val')\n",
    "    \n",
    "    # prepare the net for training\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    if verbose: print('START TRAIN.')\n",
    "        \n",
    "    start_time = timeit.default_timer()\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch::', epoch+1, '/', num_epochs)\n",
    "        running_loss = 0.0\n",
    "        # train on batches of data\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            out = model(data)\n",
    "            \n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            out_flatten = out.flatten()\n",
    "            y_flatten = data.y.flatten()\n",
    "            \n",
    "            loss = criterion(out_flatten, y_flatten)\n",
    "            print('\\tBatch:', i+1, '/', len(train_loader), ': Loss:', loss.data)\n",
    "            writer1.add_scalar('data', loss.item(), epoch)\n",
    "            # backward pass to calculate the weight gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # store loss for each batch\n",
    "            train_loss_history.append(loss.data)\n",
    "            \n",
    "            # log the loss every log_nth iterations\n",
    "            running_loss += loss.item()\n",
    "            if i % log_nth == log_nth - 1:\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.5f' \n",
    "                          %(epoch + 1, i + 1, running_loss / log_nth))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        #Compute val loss after each epoch\n",
    "        train_loss_epoch = np.mean([x.cpu().numpy() for x in train_loss_history[-i-1:]])\n",
    "        print('Loss on TRAIN data (mean):', train_loss_epoch)\n",
    "\n",
    "        val_loss = val_net(model, val_loader, criterion)\n",
    "        writer1.add_scalars('data', {'train': train_loss_epoch, 'val': val_loss}, epoch)\n",
    "        #writer2.add_scalar('data/total_loss_epoch', val_loss, epoch)\n",
    "        val_loss_history.append(val_loss)\n",
    "    if verbose: print('FINISH.')\n",
    "    \n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GCNConv(128, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (lin2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:: 1 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(1224.1094, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(1166.8097, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 1195.4595091656283\n",
      "Loss on VAL data: 19.711672112071614\n",
      "\n",
      "Epoch:: 2 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(38.4393, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(14.1898, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 26.314546948391676\n",
      "Loss on VAL data: 66.94111782900741\n",
      "\n",
      "Epoch:: 3 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(8.2146, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(15.0772, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 11.645911956107131\n",
      "Loss on VAL data: 117.79503477213507\n",
      "\n",
      "Epoch:: 4 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(19.7133, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(25.7001, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 22.706724088189418\n",
      "Loss on VAL data: 127.24085857340624\n",
      "\n",
      "Epoch:: 5 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(20.3004, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(16.4946, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 18.397484672890485\n",
      "Loss on VAL data: 105.95125060571523\n",
      "\n",
      "Epoch:: 6 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(9.2725, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(5.2661, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 7.269305960248241\n",
      "Loss on VAL data: 78.3101658106974\n",
      "\n",
      "Epoch:: 7 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.5795, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.4242, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.501839281485056\n",
      "Loss on VAL data: 59.548184034557984\n",
      "\n",
      "Epoch:: 8 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(8.4511, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(8.6851, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 8.568081889958288\n",
      "Loss on VAL data: 53.664106068091975\n",
      "\n",
      "Epoch:: 9 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(11.4175, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(9.2521, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 10.33479671742188\n",
      "Loss on VAL data: 59.24332739020775\n",
      "\n",
      "Epoch:: 10 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(8.8912, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(6.0863, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 7.4887470398617095\n",
      "Loss on VAL data: 73.29351489290143\n",
      "\n",
      "Epoch:: 11 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.9723, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.2245, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.598435045426897\n",
      "Loss on VAL data: 90.57166301861577\n",
      "\n",
      "Epoch:: 12 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.0783, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(5.2721, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.675229692888291\n",
      "Loss on VAL data: 103.55470087031188\n",
      "\n",
      "Epoch:: 13 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(5.4079, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(6.3679, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 5.887897848200421\n",
      "Loss on VAL data: 106.79096880369183\n",
      "\n",
      "Epoch:: 14 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(5.7322, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(5.4544, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 5.5933132257956295\n",
      "Loss on VAL data: 100.60345617395008\n",
      "\n",
      "Epoch:: 15 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.5078, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.8743, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.191028393492009\n",
      "Loss on VAL data: 90.08810961006782\n",
      "\n",
      "Epoch:: 16 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6839, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5225, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.6031912310428145\n",
      "Loss on VAL data: 81.09891553106488\n",
      "\n",
      "Epoch:: 17 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.0566, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.1525, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.1045535463041425\n",
      "Loss on VAL data: 77.22198272847344\n",
      "\n",
      "Epoch:: 18 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.4803, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.4119, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.446096662656305\n",
      "Loss on VAL data: 79.23910682352849\n",
      "\n",
      "Epoch:: 19 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(4.1076, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(4.0354, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 4.071488123586185\n",
      "Loss on VAL data: 85.53318954666254\n",
      "\n",
      "Epoch:: 20 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5167, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.7580, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.637350908746235\n",
      "Loss on VAL data: 92.8305868113789\n",
      "\n",
      "Epoch:: 21 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4635, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.8580, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.660734456037404\n",
      "Loss on VAL data: 97.57101515864333\n",
      "\n",
      "Epoch:: 22 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.7552, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.8880, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.8215891760135365\n",
      "Loss on VAL data: 97.756361756349\n",
      "\n",
      "Epoch:: 23 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.8268, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.6150, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.7209110668308742\n",
      "Loss on VAL data: 94.08750772301357\n",
      "\n",
      "Epoch:: 24 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.6541, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3685, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.5112793042717105\n",
      "Loss on VAL data: 89.20104914303516\n",
      "\n",
      "Epoch:: 25 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5631, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4113, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4872020189908204\n",
      "Loss on VAL data: 85.8265381800342\n",
      "\n",
      "Epoch:: 26 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5961, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5617, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.578855788176446\n",
      "Loss on VAL data: 85.38305950565847\n",
      "\n",
      "Epoch:: 27 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5546, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5778, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.5661800048753918\n",
      "Loss on VAL data: 87.57493516352918\n",
      "\n",
      "Epoch:: 28 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4291, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.5015, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4653334350612983\n",
      "Loss on VAL data: 90.81928354042077\n",
      "\n",
      "Epoch:: 29 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3934, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4669, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.430155874027367\n",
      "Loss on VAL data: 93.19956122764904\n",
      "\n",
      "Epoch:: 30 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4747, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4545, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.464645982252879\n",
      "Loss on VAL data: 93.5186289076929\n",
      "\n",
      "Epoch:: 31 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.5244, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4029, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4636354046366153\n",
      "Loss on VAL data: 91.9512877355428\n",
      "\n",
      "Epoch:: 32 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4783, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3668, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4225607816890546\n",
      "Loss on VAL data: 89.75160562296702\n",
      "\n",
      "Epoch:: 33 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4179, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4056, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4117810243190583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 88.31535680156844\n",
      "\n",
      "Epoch:: 34 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3926, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4573, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4249357743227713\n",
      "Loss on VAL data: 88.33868037641692\n",
      "\n",
      "Epoch:: 35 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3720, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4474, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.4097054608510122\n",
      "Loss on VAL data: 89.5552044082528\n",
      "\n",
      "Epoch:: 36 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3568, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.4037, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.380248668930547\n",
      "Loss on VAL data: 91.05330217958901\n",
      "\n",
      "Epoch:: 37 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3785, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3779, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3781898851769965\n",
      "Loss on VAL data: 91.8846188260898\n",
      "\n",
      "Epoch:: 38 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4123, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3664, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.389321948288499\n",
      "Loss on VAL data: 91.64620517194992\n",
      "\n",
      "Epoch:: 39 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.4088, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3604, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.384623443874519\n",
      "Loss on VAL data: 90.67388100881227\n",
      "\n",
      "Epoch:: 40 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3768, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3733, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3750508572154923\n",
      "Loss on VAL data: 89.7111184808176\n",
      "\n",
      "Epoch:: 41 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3542, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3930, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3736032393544058\n",
      "Loss on VAL data: 89.36186271746537\n",
      "\n",
      "Epoch:: 42 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3473, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3897, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3684805397898394\n",
      "Loss on VAL data: 89.7441185757807\n",
      "\n",
      "Epoch:: 43 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3483, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3672, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.357779398177482\n",
      "Loss on VAL data: 90.49391095477927\n",
      "\n",
      "Epoch:: 44 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3591, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3503, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.354689458524633\n",
      "Loss on VAL data: 91.06806376136895\n",
      "\n",
      "Epoch:: 45 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3703, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3452, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3577473953894232\n",
      "Loss on VAL data: 91.12241959114083\n",
      "\n",
      "Epoch:: 46 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3662, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3469, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.356535711880508\n",
      "Loss on VAL data: 90.7220995861782\n",
      "\n",
      "Epoch:: 47 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3510, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3532, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.352120931904626\n",
      "Loss on VAL data: 90.2331600279395\n",
      "\n",
      "Epoch:: 48 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3398, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3572, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.348520280735182\n",
      "Loss on VAL data: 90.04295030288745\n",
      "\n",
      "Epoch:: 49 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3366, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3522, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.34435395047098\n",
      "Loss on VAL data: 90.24162875368218\n",
      "\n",
      "Epoch:: 50 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3378, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3425, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3401422400452256\n",
      "Loss on VAL data: 90.61216413821694\n",
      "\n",
      "Epoch:: 51 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3406, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3367, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.338628231137916\n",
      "Loss on VAL data: 90.86396698888252\n",
      "\n",
      "Epoch:: 52 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3402, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3361, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3381366563338517\n",
      "Loss on VAL data: 90.83514981891032\n",
      "\n",
      "Epoch:: 53 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3340, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3380, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.335969167630201\n",
      "Loss on VAL data: 90.59227298661551\n",
      "\n",
      "Epoch:: 54 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3264, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3394, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3328553945087664\n",
      "Loss on VAL data: 90.35160141158332\n",
      "\n",
      "Epoch:: 55 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3222, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3375, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3298424650742358\n",
      "Loss on VAL data: 90.29207868464698\n",
      "\n",
      "Epoch:: 56 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3215, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3324, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.326947935070664\n",
      "Loss on VAL data: 90.42899076708062\n",
      "\n",
      "Epoch:: 57 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3220, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3273, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.324680437494217\n",
      "Loss on VAL data: 90.62673787460444\n",
      "\n",
      "Epoch:: 58 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3214, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3248, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.323120473254388\n",
      "Loss on VAL data: 90.71878502753388\n",
      "\n",
      "Epoch:: 59 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3196, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3241, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.321853048382976\n",
      "Loss on VAL data: 90.63414134637765\n",
      "\n",
      "Epoch:: 60 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3168, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3235, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3201579876698477\n",
      "Loss on VAL data: 90.47172848331648\n",
      "\n",
      "Epoch:: 61 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3141, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3221, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3181415102570204\n",
      "Loss on VAL data: 90.37787580936423\n",
      "\n",
      "Epoch:: 62 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3125, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3198, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3161129813631676\n",
      "Loss on VAL data: 90.42145364109626\n",
      "\n",
      "Epoch:: 63 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3111, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3172, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3141694319388\n",
      "Loss on VAL data: 90.55815515048992\n",
      "\n",
      "Epoch:: 64 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3099, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3155, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3126898109125484\n",
      "Loss on VAL data: 90.66888858047474\n",
      "\n",
      "Epoch:: 65 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3082, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3146, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3113657010747515\n",
      "Loss on VAL data: 90.67614678773259\n",
      "\n",
      "Epoch:: 66 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3060, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3135, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.309719931505338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 90.59258972122193\n",
      "\n",
      "Epoch:: 67 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3038, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3120, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3079020551113425\n",
      "Loss on VAL data: 90.50440704172395\n",
      "\n",
      "Epoch:: 68 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3022, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3103, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3062399305782195\n",
      "Loss on VAL data: 90.48285975144745\n",
      "\n",
      "Epoch:: 69 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.3010, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3086, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.30480534994744\n",
      "Loss on VAL data: 90.53614336364035\n",
      "\n",
      "Epoch:: 70 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2997, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3071, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3034142641017965\n",
      "Loss on VAL data: 90.60447790833545\n",
      "\n",
      "Epoch:: 71 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2982, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3057, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3019303595590976\n",
      "Loss on VAL data: 90.63842737339571\n",
      "\n",
      "Epoch:: 72 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2968, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3041, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.3004571280902826\n",
      "Loss on VAL data: 90.62775043396964\n",
      "\n",
      "Epoch:: 73 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2957, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3025, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2990752032304678\n",
      "Loss on VAL data: 90.60409296519391\n",
      "\n",
      "Epoch:: 74 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2945, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.3010, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2977858693373494\n",
      "Loss on VAL data: 90.6084643718413\n",
      "\n",
      "Epoch:: 75 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2933, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2997, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2964997063875527\n",
      "Loss on VAL data: 90.6462972831111\n",
      "\n",
      "Epoch:: 76 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2918, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2984, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2951379434976706\n",
      "Loss on VAL data: 90.6850814153306\n",
      "\n",
      "Epoch:: 77 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2905, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2969, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.293728677127568\n",
      "Loss on VAL data: 90.70097488631427\n",
      "\n",
      "Epoch:: 78 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2893, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2953, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.292300131134332\n",
      "Loss on VAL data: 90.6976150744185\n",
      "\n",
      "Epoch:: 79 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2881, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2934, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.290743032311375\n",
      "Loss on VAL data: 90.69535680656838\n",
      "\n",
      "Epoch:: 80 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2869, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2910, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2889534724355376\n",
      "Loss on VAL data: 90.71190898995307\n",
      "\n",
      "Epoch:: 81 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2858, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2883, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2870868868616165\n",
      "Loss on VAL data: 90.74639837451237\n",
      "\n",
      "Epoch:: 82 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2848, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2854, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.285119256804123\n",
      "Loss on VAL data: 90.78478130548888\n",
      "\n",
      "Epoch:: 83 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2838, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2821, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.282958239828468\n",
      "Loss on VAL data: 90.81249438591844\n",
      "\n",
      "Epoch:: 84 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2828, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2790, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.280890374974521\n",
      "Loss on VAL data: 90.83356761444821\n",
      "\n",
      "Epoch:: 85 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2819, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2768, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2793301232946126\n",
      "Loss on VAL data: 90.85859992890687\n",
      "\n",
      "Epoch:: 86 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2809, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2746, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.277781541815953\n",
      "Loss on VAL data: 90.89123029755775\n",
      "\n",
      "Epoch:: 87 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2800, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2725, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2762745083549167\n",
      "Loss on VAL data: 90.92574352860281\n",
      "\n",
      "Epoch:: 88 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2792, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2705, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2748152509012396\n",
      "Loss on VAL data: 90.95919721590785\n",
      "\n",
      "Epoch:: 89 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2784, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2685, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.27343616697885\n",
      "Loss on VAL data: 90.98961618834149\n",
      "\n",
      "Epoch:: 90 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2776, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2673, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2724862455176726\n",
      "Loss on VAL data: 91.01905071045572\n",
      "\n",
      "Epoch:: 91 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2770, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2664, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.271714872526042\n",
      "Loss on VAL data: 91.0520283580846\n",
      "\n",
      "Epoch:: 92 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2764, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2655, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.270980264132996\n",
      "Loss on VAL data: 91.08947191351119\n",
      "\n",
      "Epoch:: 93 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2757, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2648, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2702338874476453\n",
      "Loss on VAL data: 91.12574806622273\n",
      "\n",
      "Epoch:: 94 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2749, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2640, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2694508080642106\n",
      "Loss on VAL data: 91.15361768850063\n",
      "\n",
      "Epoch:: 95 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2741, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2632, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.268652841991579\n",
      "Loss on VAL data: 91.18531959706574\n",
      "\n",
      "Epoch:: 96 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2733, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2624, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2678453820387983\n",
      "Loss on VAL data: 91.22471366665086\n",
      "\n",
      "Epoch:: 97 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2724, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2617, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.267048712088445\n",
      "Loss on VAL data: 91.27076547887775\n",
      "\n",
      "Epoch:: 98 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2716, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2609, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2662598343634186\n",
      "Loss on VAL data: 91.32150520559627\n",
      "\n",
      "Epoch:: 99 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2707, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2602, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2654525988222147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 91.3731191460998\n",
      "\n",
      "Epoch:: 100 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2699, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2594, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2646492587875793\n",
      "Loss on VAL data: 91.42877840279773\n",
      "\n",
      "Epoch:: 101 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2690, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2586, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.263810745275893\n",
      "Loss on VAL data: 91.50362964746763\n",
      "\n",
      "Epoch:: 102 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2681, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2578, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.262978312404788\n",
      "Loss on VAL data: 91.60062795615845\n",
      "\n",
      "Epoch:: 103 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2669, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2570, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.261965623569142\n",
      "Loss on VAL data: 91.71980012253802\n",
      "\n",
      "Epoch:: 104 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2656, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2562, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2608971611507105\n",
      "Loss on VAL data: 91.8454695246045\n",
      "\n",
      "Epoch:: 105 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2649, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2553, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2600976969689546\n",
      "Loss on VAL data: 91.97851939037126\n",
      "\n",
      "Epoch:: 106 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2633, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2544, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2588489067374473\n",
      "Loss on VAL data: 92.15949825220794\n",
      "\n",
      "Epoch:: 107 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2618, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2534, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2575960283261844\n",
      "Loss on VAL data: 92.34407200766093\n",
      "\n",
      "Epoch:: 108 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2605, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2526, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2565967265803546\n",
      "Loss on VAL data: 92.50532196608698\n",
      "\n",
      "Epoch:: 109 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2596, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2518, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2557320511860572\n",
      "Loss on VAL data: 92.65080156817015\n",
      "\n",
      "Epoch:: 110 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2589, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2510, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2549241034395817\n",
      "Loss on VAL data: 92.79955667481687\n",
      "\n",
      "Epoch:: 111 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2582, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2501, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.254146721594531\n",
      "Loss on VAL data: 92.94592767437778\n",
      "\n",
      "Epoch:: 112 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2576, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2494, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2534802898604633\n",
      "Loss on VAL data: 93.07590151345796\n",
      "\n",
      "Epoch:: 113 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2570, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2487, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2528522251584477\n",
      "Loss on VAL data: 93.1781321050277\n",
      "\n",
      "Epoch:: 114 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2565, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2481, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2522618949766393\n",
      "Loss on VAL data: 93.26438993295227\n",
      "\n",
      "Epoch:: 115 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2559, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2475, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2517108517124753\n",
      "Loss on VAL data: 93.35347440249798\n",
      "\n",
      "Epoch:: 116 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2553, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2470, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2511557412438092\n",
      "Loss on VAL data: 93.45006184539757\n",
      "\n",
      "Epoch:: 117 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2548, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2465, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2506305132089754\n",
      "Loss on VAL data: 93.5377515801793\n",
      "\n",
      "Epoch:: 118 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2543, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2460, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.250144987024353\n",
      "Loss on VAL data: 93.60848822610585\n",
      "\n",
      "Epoch:: 119 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2538, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2455, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.249655953209364\n",
      "Loss on VAL data: 93.66266772017248\n",
      "\n",
      "Epoch:: 120 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2534, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2450, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2491974323563597\n",
      "Loss on VAL data: 93.71004792258186\n",
      "\n",
      "Epoch:: 121 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2530, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2445, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2487487768683456\n",
      "Loss on VAL data: 93.76041305115109\n",
      "\n",
      "Epoch:: 122 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2526, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2440, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2483086717629583\n",
      "Loss on VAL data: 93.81648495094\n",
      "\n",
      "Epoch:: 123 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2523, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2435, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.247913501700705\n",
      "Loss on VAL data: 93.85563746884357\n",
      "\n",
      "Epoch:: 124 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2519, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2432, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2475672974876577\n",
      "Loss on VAL data: 93.87301348184587\n",
      "\n",
      "Epoch:: 125 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2515, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2428, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2471491979448013\n",
      "Loss on VAL data: 93.89245312473402\n",
      "\n",
      "Epoch:: 126 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2512, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2424, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.246763680829158\n",
      "Loss on VAL data: 93.9295721089863\n",
      "\n",
      "Epoch:: 127 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2508, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2420, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.246400844760884\n",
      "Loss on VAL data: 93.96458292273935\n",
      "\n",
      "Epoch:: 128 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2505, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2416, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.24605211507742\n",
      "Loss on VAL data: 93.99023176379553\n",
      "\n",
      "Epoch:: 129 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2501, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2413, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.245697170103846\n",
      "Loss on VAL data: 93.99857620870995\n",
      "\n",
      "Epoch:: 130 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2498, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2409, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.245330717675953\n",
      "Loss on VAL data: 94.00682246447813\n",
      "\n",
      "Epoch:: 131 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2494, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2405, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.244972682812844\n",
      "Loss on VAL data: 94.03616022722939\n",
      "\n",
      "Epoch:: 132 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2492, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2401, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.244627169656141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 94.05821452535024\n",
      "\n",
      "Epoch:: 133 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2489, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2398, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.244331712508108\n",
      "Loss on VAL data: 94.0676412096099\n",
      "\n",
      "Epoch:: 134 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2485, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2394, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.24397389078387\n",
      "Loss on VAL data: 94.07538220474031\n",
      "\n",
      "Epoch:: 135 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2482, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2391, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2436465163126584\n",
      "Loss on VAL data: 94.09723740186386\n",
      "\n",
      "Epoch:: 136 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2479, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2387, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.243310898768337\n",
      "Loss on VAL data: 94.13041970643629\n",
      "\n",
      "Epoch:: 137 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2477, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2383, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2429867994107617\n",
      "Loss on VAL data: 94.15640313012359\n",
      "\n",
      "Epoch:: 138 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2474, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2380, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2426828899132714\n",
      "Loss on VAL data: 94.16451544606981\n",
      "\n",
      "Epoch:: 139 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2470, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2377, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2423494336351\n",
      "Loss on VAL data: 94.1655336398399\n",
      "\n",
      "Epoch:: 140 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2467, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2374, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.24201885296757\n",
      "Loss on VAL data: 94.17664379074847\n",
      "\n",
      "Epoch:: 141 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2464, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2370, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.241680550933969\n",
      "Loss on VAL data: 94.20310290047472\n",
      "\n",
      "Epoch:: 142 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2461, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2366, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2413584483265128\n",
      "Loss on VAL data: 94.23994411440584\n",
      "\n",
      "Epoch:: 143 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2459, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2363, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2410761866659508\n",
      "Loss on VAL data: 94.27594118163672\n",
      "\n",
      "Epoch:: 144 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2455, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2360, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.240773281891765\n",
      "Loss on VAL data: 94.30332767327529\n",
      "\n",
      "Epoch:: 145 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2452, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2357, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2404325763275263\n",
      "Loss on VAL data: 94.33625895277889\n",
      "\n",
      "Epoch:: 146 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2449, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2354, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.240118561746454\n",
      "Loss on VAL data: 94.38658046540111\n",
      "\n",
      "Epoch:: 147 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2447, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2349, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.239800608774801\n",
      "Loss on VAL data: 94.4421750961565\n",
      "\n",
      "Epoch:: 148 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2444, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2346, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2395110458597878\n",
      "Loss on VAL data: 94.45646099447043\n",
      "\n",
      "Epoch:: 149 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2441, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2344, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.239207582345365\n",
      "Loss on VAL data: 94.44883879403028\n",
      "\n",
      "Epoch:: 150 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2437, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2341, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2388811205985037\n",
      "Loss on VAL data: 94.46654177959032\n",
      "\n",
      "Epoch:: 151 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2434, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2337, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.238573391163987\n",
      "Loss on VAL data: 94.51023864699374\n",
      "\n",
      "Epoch:: 152 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2432, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2333, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2382601969013183\n",
      "Loss on VAL data: 94.55497956847664\n",
      "\n",
      "Epoch:: 153 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2429, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2330, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.237968334512421\n",
      "Loss on VAL data: 94.57723133986627\n",
      "\n",
      "Epoch:: 154 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2426, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2327, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.237662386257859\n",
      "Loss on VAL data: 94.59191605911074\n",
      "\n",
      "Epoch:: 155 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2423, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2324, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.237353371659089\n",
      "Loss on VAL data: 94.62392739483009\n",
      "\n",
      "Epoch:: 156 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2420, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2321, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2370459810801107\n",
      "Loss on VAL data: 94.6693730176789\n",
      "\n",
      "Epoch:: 157 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2417, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2318, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.236742281104547\n",
      "Loss on VAL data: 94.70734377325742\n",
      "\n",
      "Epoch:: 158 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2415, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2314, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2364441493877862\n",
      "Loss on VAL data: 94.73190282969146\n",
      "\n",
      "Epoch:: 159 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2412, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2311, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2361472950568357\n",
      "Loss on VAL data: 94.7394435872701\n",
      "\n",
      "Epoch:: 160 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2409, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2308, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.235850299835822\n",
      "Loss on VAL data: 94.76216685943511\n",
      "\n",
      "Epoch:: 161 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2406, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2305, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.23554175200272\n",
      "Loss on VAL data: 94.80341669632195\n",
      "\n",
      "Epoch:: 162 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2403, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2302, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2352370723474464\n",
      "Loss on VAL data: 94.83740761955892\n",
      "\n",
      "Epoch:: 163 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2400, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2298, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2349426142835576\n",
      "Loss on VAL data: 94.86459553179138\n",
      "\n",
      "Epoch:: 164 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2398, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2295, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2346505291187837\n",
      "Loss on VAL data: 94.8892665012977\n",
      "\n",
      "Epoch:: 165 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2395, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2293, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2343549411565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 94.911685288807\n",
      "\n",
      "Epoch:: 166 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2392, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2289, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.234051689292673\n",
      "Loss on VAL data: 94.94802208751992\n",
      "\n",
      "Epoch:: 167 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2389, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2286, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2337558331080056\n",
      "Loss on VAL data: 94.98694981456295\n",
      "\n",
      "Epoch:: 168 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2386, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2283, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2334665133735223\n",
      "Loss on VAL data: 95.0077886208713\n",
      "\n",
      "Epoch:: 169 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2383, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2280, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2331681585410585\n",
      "Loss on VAL data: 95.03065467493714\n",
      "\n",
      "Epoch:: 170 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2381, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2277, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.232876003467279\n",
      "Loss on VAL data: 95.06083019536499\n",
      "\n",
      "Epoch:: 171 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2378, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2274, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.232582652266673\n",
      "Loss on VAL data: 95.10117160910238\n",
      "\n",
      "Epoch:: 172 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2375, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2271, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.232290467676228\n",
      "Loss on VAL data: 95.1320399840814\n",
      "\n",
      "Epoch:: 173 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2372, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2268, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.232002044942325\n",
      "Loss on VAL data: 95.16143823999431\n",
      "\n",
      "Epoch:: 174 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2370, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2265, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2317181426098402\n",
      "Loss on VAL data: 95.19701644581056\n",
      "\n",
      "Epoch:: 175 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2367, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2261, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.231425907885893\n",
      "Loss on VAL data: 95.23347009408828\n",
      "\n",
      "Epoch:: 176 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2364, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2258, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2311340517848324\n",
      "Loss on VAL data: 95.25970003582883\n",
      "\n",
      "Epoch:: 177 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2362, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2255, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2308497040803923\n",
      "Loss on VAL data: 95.28913159003532\n",
      "\n",
      "Epoch:: 178 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2359, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2252, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2305555093393625\n",
      "Loss on VAL data: 95.34009272921422\n",
      "\n",
      "Epoch:: 179 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2356, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2249, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.230272075974851\n",
      "Loss on VAL data: 95.36607857488407\n",
      "\n",
      "Epoch:: 180 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2354, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2246, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2299968809841832\n",
      "Loss on VAL data: 95.37485997856557\n",
      "\n",
      "Epoch:: 181 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2351, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2244, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.229721991192199\n",
      "Loss on VAL data: 95.40172358731593\n",
      "\n",
      "Epoch:: 182 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2348, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2240, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.229408162823823\n",
      "Loss on VAL data: 95.4575876344601\n",
      "\n",
      "Epoch:: 183 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2345, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2237, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2291245423434978\n",
      "Loss on VAL data: 95.5072636763389\n",
      "\n",
      "Epoch:: 184 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2343, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2234, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.228846753628054\n",
      "Loss on VAL data: 95.5286281517519\n",
      "\n",
      "Epoch:: 185 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2340, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2231, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2285651254425902\n",
      "Loss on VAL data: 95.53387883404135\n",
      "\n",
      "Epoch:: 186 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2337, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2228, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2282793385285227\n",
      "Loss on VAL data: 95.56627202056501\n",
      "\n",
      "Epoch:: 187 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2335, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2225, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.227993678896775\n",
      "Loss on VAL data: 95.61722459876898\n",
      "\n",
      "Epoch:: 188 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2332, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2222, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.227708545957739\n",
      "Loss on VAL data: 95.66160949213126\n",
      "\n",
      "Epoch:: 189 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2329, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2219, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.227427799591765\n",
      "Loss on VAL data: 95.69085110898489\n",
      "\n",
      "Epoch:: 190 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2327, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2216, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.227150178806162\n",
      "Loss on VAL data: 95.71326677233883\n",
      "\n",
      "Epoch:: 191 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2324, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2213, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2268679755706713\n",
      "Loss on VAL data: 95.74944317836709\n",
      "\n",
      "Epoch:: 192 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2321, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2210, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2265804315396425\n",
      "Loss on VAL data: 95.79121579661023\n",
      "\n",
      "Epoch:: 193 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2319, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2207, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.226302755195184\n",
      "Loss on VAL data: 95.83170262082949\n",
      "\n",
      "Epoch:: 194 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2316, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2204, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2260322532992936\n",
      "Loss on VAL data: 95.85983695110167\n",
      "\n",
      "Epoch:: 195 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2313, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2202, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2257618453119656\n",
      "Loss on VAL data: 95.88265982426076\n",
      "\n",
      "Epoch:: 196 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2311, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2199, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2254777500851675\n",
      "Loss on VAL data: 95.92710895212326\n",
      "\n",
      "Epoch:: 197 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2308, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2196, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.225201686782073\n",
      "Loss on VAL data: 95.97135413309559\n",
      "\n",
      "Epoch:: 198 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2306, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2193, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2249368745787796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 95.9987965192322\n",
      "\n",
      "Epoch:: 199 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2303, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2190, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.224661018307338\n",
      "Loss on VAL data: 96.02950084753708\n",
      "\n",
      "Epoch:: 200 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2300, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2187, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2243822943741134\n",
      "Loss on VAL data: 96.07347174590537\n",
      "\n",
      "Epoch:: 201 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2298, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2184, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2241079761008096\n",
      "Loss on VAL data: 96.1095929390112\n",
      "\n",
      "Epoch:: 202 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2295, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2181, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2238436625539086\n",
      "Loss on VAL data: 96.15235417624103\n",
      "\n",
      "Epoch:: 203 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2293, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2178, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.223560190759054\n",
      "Loss on VAL data: 96.19465528084324\n",
      "\n",
      "Epoch:: 204 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2290, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2176, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2232927774671545\n",
      "Loss on VAL data: 96.23232423754492\n",
      "\n",
      "Epoch:: 205 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2288, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2173, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.223014045555759\n",
      "Loss on VAL data: 96.26044619315257\n",
      "\n",
      "Epoch:: 206 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2285, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2170, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2227493893957435\n",
      "Loss on VAL data: 96.29776927393478\n",
      "\n",
      "Epoch:: 207 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2283, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2167, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.22247286541043\n",
      "Loss on VAL data: 96.34213835177036\n",
      "\n",
      "Epoch:: 208 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2280, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2164, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.222199230814678\n",
      "Loss on VAL data: 96.38450983050684\n",
      "\n",
      "Epoch:: 209 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2277, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2161, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.221928943881057\n",
      "Loss on VAL data: 96.42642164683025\n",
      "\n",
      "Epoch:: 210 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2275, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2158, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2216569922624556\n",
      "Loss on VAL data: 96.47247715861154\n",
      "\n",
      "Epoch:: 211 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2272, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2156, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.22139320041541\n",
      "Loss on VAL data: 96.51671247154424\n",
      "\n",
      "Epoch:: 212 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2270, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2153, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.221129217913263\n",
      "Loss on VAL data: 96.56129039462202\n",
      "\n",
      "Epoch:: 213 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2267, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2150, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2208551798171214\n",
      "Loss on VAL data: 96.61123940798954\n",
      "\n",
      "Epoch:: 214 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2265, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2147, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.220609327524794\n",
      "Loss on VAL data: 96.66077487841046\n",
      "\n",
      "Epoch:: 215 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2262, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2144, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2203190737778415\n",
      "Loss on VAL data: 96.711189775575\n",
      "\n",
      "Epoch:: 216 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2260, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2141, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.220043287175999\n",
      "Loss on VAL data: 96.76413775169397\n",
      "\n",
      "Epoch:: 217 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2257, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2138, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.219780564269729\n",
      "Loss on VAL data: 96.81910996526274\n",
      "\n",
      "Epoch:: 218 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2255, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2135, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2195099210635636\n",
      "Loss on VAL data: 96.8835155481404\n",
      "\n",
      "Epoch:: 219 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2252, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2132, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.219236761184048\n",
      "Loss on VAL data: 96.95409098884268\n",
      "\n",
      "Epoch:: 220 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2250, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2130, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.21897015042384\n",
      "Loss on VAL data: 97.0151337469423\n",
      "\n",
      "Epoch:: 221 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2247, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2127, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.218705964575469\n",
      "Loss on VAL data: 97.05282797247116\n",
      "\n",
      "Epoch:: 222 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2245, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2124, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.218446260796349\n",
      "Loss on VAL data: 97.09580037812964\n",
      "\n",
      "Epoch:: 223 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2243, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2121, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.218179979615666\n",
      "Loss on VAL data: 97.16471646729968\n",
      "\n",
      "Epoch:: 224 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2240, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2118, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2179147983798435\n",
      "Loss on VAL data: 97.23857591158077\n",
      "\n",
      "Epoch:: 225 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2238, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2115, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.217646877538186\n",
      "Loss on VAL data: 97.2693989740131\n",
      "\n",
      "Epoch:: 226 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2235, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2113, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2173979787176625\n",
      "Loss on VAL data: 97.289014917216\n",
      "\n",
      "Epoch:: 227 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2233, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2110, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2171279360848506\n",
      "Loss on VAL data: 97.35095065913622\n",
      "\n",
      "Epoch:: 228 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2230, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2107, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.216869187872094\n",
      "Loss on VAL data: 97.41439625220578\n",
      "\n",
      "Epoch:: 229 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2228, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2104, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.216609978203957\n",
      "Loss on VAL data: 97.4517466341777\n",
      "\n",
      "Epoch:: 230 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2225, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2102, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.216364517536249\n",
      "Loss on VAL data: 97.48788188126257\n",
      "\n",
      "Epoch:: 231 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2223, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2099, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2161272197719355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on VAL data: 97.54115330584811\n",
      "\n",
      "Epoch:: 232 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2220, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2096, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2158291752115495\n",
      "Loss on VAL data: 97.61868517337689\n",
      "\n",
      "Epoch:: 233 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2218, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2094, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.215590008450177\n",
      "Loss on VAL data: 97.66714241512157\n",
      "\n",
      "Epoch:: 234 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2216, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2091, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.21533340408899\n",
      "Loss on VAL data: 97.68771598106248\n",
      "\n",
      "Epoch:: 235 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2213, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2088, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.215074382205361\n",
      "Loss on VAL data: 97.72537505870976\n",
      "\n",
      "Epoch:: 236 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2211, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2086, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.214827014885766\n",
      "Loss on VAL data: 97.78197761486105\n",
      "\n",
      "Epoch:: 237 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2209, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2083, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2145595245684877\n",
      "Loss on VAL data: 97.81318014877694\n",
      "\n",
      "Epoch:: 238 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2206, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2080, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2143273298485333\n",
      "Loss on VAL data: 97.80917458691295\n",
      "\n",
      "Epoch:: 239 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2204, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2078, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.214097764495042\n",
      "Loss on VAL data: 97.83971509897295\n",
      "\n",
      "Epoch:: 240 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2201, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2075, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2138021607998697\n",
      "Loss on VAL data: 97.91219018025912\n",
      "\n",
      "Epoch:: 241 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2199, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2072, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2135628960853317\n",
      "Loss on VAL data: 97.94894949482097\n",
      "\n",
      "Epoch:: 242 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2196, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2070, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2133144198657178\n",
      "Loss on VAL data: 97.9535801378896\n",
      "\n",
      "Epoch:: 243 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2194, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2067, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2130569366737887\n",
      "Loss on VAL data: 97.97814405809355\n",
      "\n",
      "Epoch:: 244 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2192, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2064, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2127977809228807\n",
      "Loss on VAL data: 98.01918072524467\n",
      "\n",
      "Epoch:: 245 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2189, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2061, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2125319584071965\n",
      "Loss on VAL data: 98.04912516355766\n",
      "\n",
      "Epoch:: 246 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2187, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2059, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2122954728394193\n",
      "Loss on VAL data: 98.07637893658507\n",
      "\n",
      "Epoch:: 247 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2185, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2056, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.2120566837979583\n",
      "Loss on VAL data: 98.13985604671974\n",
      "\n",
      "Epoch:: 248 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2182, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2054, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.211821188885213\n",
      "Loss on VAL data: 98.197189074875\n",
      "\n",
      "Epoch:: 249 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2180, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2051, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.211542929910979\n",
      "Loss on VAL data: 98.21845432569508\n",
      "\n",
      "Epoch:: 250 / 250\n",
      "\tBatch: 1 / 2 : Loss: tensor(3.2177, device='cuda:0', dtype=torch.float64)\n",
      "\tBatch: 2 / 2 : Loss: tensor(3.2049, device='cuda:0', dtype=torch.float64)\n",
      "Loss on TRAIN data (mean): 3.211316769932089\n",
      "Loss on VAL data: 98.26059924988004\n"
     ]
    }
   ],
   "source": [
    "num_train = 2\n",
    "OverfitSampler = SequentialSampler(range(num_train))\n",
    "\n",
    "overfit_train_loader = DataLoader(train, batch_size=1, \n",
    "                                  shuffle=False, sampler=OverfitSampler)\n",
    "overfit_val_loader = DataLoader(val, batch_size=1, shuffle=False, sampler=SequentialSampler(range(3)))\n",
    "\n",
    "\n",
    "# Load model and run the solver\n",
    "overfit_model = Net(in_channels=train[0].num_features, \n",
    "                    out_channels=train[0].y.shape[1])\n",
    "\n",
    "print(overfit_model)\n",
    "overfit_model.double()\n",
    "overfit_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(overfit_model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                       eps=1e-8, weight_decay=0.0)\n",
    "\n",
    "\n",
    "train_loss_history, val_loss_history = train_net(overfit_model, overfit_train_loader, overfit_val_loader, optimizer, criterion, \n",
    "                               num_epochs=250, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_history_reduced = [i for idx, i in enumerate(train_loss_history) if idx%2==0]\n",
    "\n",
    "print(len(train_loss_history_reduced), len(val_loss_history))\n",
    "plt.plot(list(range(250)), train_loss_history_reduced, '-')\n",
    "plt.plot(list(range(250)), val_loss_history, '-')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_model.double()\n",
    "overfit_model.cpu()\n",
    "overfit_model.eval()\n",
    "\n",
    "image = cv2.imread('DAVIS_2016/DAVIS/Annotations/480p/bear/00001.png')\n",
    "sample = next(iter(overfit_train_loader))\n",
    "y = sample.y.detach().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = overfit_model(sample).detach().numpy()\n",
    "\n",
    "contour = np.load('pg_datasets/DAVIS_2016/raw/Contours/bear/00000.npy')\n",
    "\n",
    "translation_ground_truth = contour + y\n",
    "translation_pred = contour + pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_translation(image, translation_ground_truth, translation_pred):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    ax.scatter(translation_ground_truth[:, 0], translation_ground_truth[:, 1], color='g')\n",
    "    ax.scatter(translation_pred[:, 0], translation_pred[:, 1], color='r')\n",
    "    \n",
    "    # Plot image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    ax.axis('image')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_translation(image, translation_ground_truth, translation_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine contour with OSVOS prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADrCAYAAABn7V3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFWpJREFUeJzt3X+wXGV9x/H3p0lIDBDyC5iQpCTUSOWPGmiKARxLQQzEH2Fa0OAPooPNTEVHi6MEbRWstsI4yNAqNBZLoMgPI0qaYmMMoR2tRgKEX0bMFVNyTUIIISGRGhP59o/zrCw3e+/dvXf37tnnfl4zd/ac5zz3nO/+uJ999tmzexURmJlZvn6v3QWYmVlrOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3ppO0rskrZe0T9I2Sd+R9Iaq7SdJWiFpj6S9ktZKOr1q+wxJIek/euz33yRdKendad/7JP2fpJeq1vdV9X+fpMckvShpu6QbJI2v2n6zpM/1OEbl2CPT+uZ0jH1pHzdLOqKP636/pA+k5TPTvu7u0ed1qf3+Hu2S9JSkn/Sy73PSbbVX0nOSNki6XNKYtP1KSQeqbwtJu3ur1YYPB701laTLgOuAvweOBX4f+AqwIG3/A+AHwGPATOA44FvAdyWd1mN3cyWd0fMYEXFbRBwREUcA5wFbK+upDUkfA64GPg4cBcwFjgdWSzqswav1trTf2cDJwBUN/O6zwOmSJlW1LQJ+VqPvG4FjgBMk/Un1BkkXAsuBrwPHR8Qk4J3ANGB6Vdc7q2+LiBiPDXsOemsaSUcBnwUujYi7I+JXEXEgIv49Ij6eul0J/DAiPhURuyJib0RcD9xKEczVrgE+R4MkjQOuAj4cEf+ZatgMvIMi7N8zkOsXEduBVRSBX6/fAN8GFqbaRqQ6bqvRdxFwD3BvWib9joBrgc9GxFcjYleq58mI+HBEbBrA1bFhxEFvzXQaMIZihN6bc4Bv1Gi/CzhD0tiqti8Dr5H0pgbrOD3V8Yopk4jYB3wn1dAwSdMoXkF0NfirtwAXp+V5wBPA1h77HgtcQPEEcBuwsOqVx4kUI/dvDqTuqmOslLRkMPuwzuSgt2aaBOyMiIN99JkMbKvRvo3i8Tihqu3XwOdpfFQ/uY86tqXtjfi2pL3AFmAH8JlGfjki/geYKOlEisC/pUa3Pwf2A98FVgIjgbekbZV6t1c6S7pD0u70/sN7q/bzjtRe+VlbVcdbI+ILjdRueXDQWzM9B0yuvJHZi53AlBrtU4CXgOd7tH8VOFbS2xqoY2cfdUxJ2wEOAqN6bB+V6nipqu38iDgSOBP4Qxp/ooBiaupDwJ9R+xXPIuCuiDgYEfspXo1Upm+eq6odgIhYmObfHwJGVO3nrogYX/XzZwOo1TLjoLdm+iHFKPz8Pvp8D7iwRvs7KObuX6xujIgDFPPtfweogTr2U4ySf0fS4RRTL2tS09PAjB6/OxPYEhEv9WgnIv4LuBn4Yp11VLsV+CBwb8/rmKaEzgLek87s2U4xjTNf0mTgp8Ave14fs3o56K1pImIP8Gngy5LOlzRW0ihJ50m6JnW7iuIslM9LmijpSEkfppjSuLyXXd8KjAbObaCOq4B/lHRuqmEGxXsD3Wl/UMx5v0XSmyWNkHQc8DfAHX3s/jrgHEmNvCFLRPwC+FPgUzU2v5fiLJwTKd7onQ28JtV6URTfJf4x4DOS/lLShHQq5iyKM5vM+uSgt6aKiGuByygC81mKee0PUZx5QjpD5A3A64DNFHPmfwHMi4gf9LLP31LMi09soI5rgE9SjL5fANalWs5OUyNExBPARcA/ALsoXgmso3iS6G2/z1LMsf9tvbVU/e73I2JrjU2LgK9ExPbqH+DGtI2IuJPiVc970vXYSfEG9lJe+eb2O3ucR79P0jEAKj7P8MlG67bOJ//jETOzvHlEb2aWuZYEfZoXfVJSl8/bNTNrr6ZP3aRP/v2M4kMp3cADFG8o1fz+DjMza61WjOhPBboi4qmI+A3FGQwLWnAcMzOrQyuCfirFWQEV3anNzMzaoK9PMA5UrQ+1HDI/JGkxsBhgBCP+eCzjWlCKmVm+9vL8zog4ur9+rQj6bl75tanT6PEFTgARsZTiHGDGaWK8Xme3oBQzs3x9L5b/bz39WjF18wAwS9LM9O17C4EVLTiOmZnVoekj+og4KOlDFN/bPQL4WvoEopmZtUErpm6IiHsp/nmCmZm1mT8Za2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZpnrN+glfU3SDkmPV7VNlLRa0qZ0OSG1S9L1krokPSrplFYWb2Zm/atnRH8zcG6PtiXAmoiYBaxJ6wDnAbPSz2LghuaUaWZmA9Vv0EfEfwO7ejQvAJal5WXA+VXtt0ThR8B4SVOaVayZmTVuoHP0x0bENoB0eUxqnwpsqerXndoOIWmxpPWS1h9g/wDLMDOz/jT7zVjVaItaHSNiaUTMiYg5oxjd5DLMzKxioEH/TGVKJl3uSO3dwPSqftOArQMvz8zMBmugQb8CWJSWFwH3VLVfnM6+mQvsqUzxmJlZe4zsr4Ok24EzgcmSuoHPAF8A7pJ0CfA0cGHqfi8wH+gCXgTe34KazcysAf0GfURc1Mums2v0DeDSwRZlZmbN40/GmpllzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpa5foNe0nRJayVtlPSEpI+k9omSVkvalC4npHZJul5Sl6RHJZ3S6ithZma9q2dEfxD4WES8FpgLXCrpJGAJsCYiZgFr0jrAecCs9LMYuKHpVZuZWd36DfqI2BYRD6XlvcBGYCqwAFiWui0Dzk/LC4BbovAjYLykKU2v3MzM6tLQHL2kGcDJwDrg2IjYBsWTAXBM6jYV2FL1a92pree+FktaL2n9AfY3XrmZmdWl7qCXdATwTeCjEfFCX11rtMUhDRFLI2JORMwZxeh6yzAzswbVFfSSRlGE/G0RcXdqfqYyJZMud6T2bmB61a9PA7Y2p1wzM2tUPWfdCLgJ2BgR11ZtWgEsSsuLgHuq2i9OZ9/MBfZUpnjMzGzojayjzxnAe4HHJG1IbZ8EvgDcJekS4GngwrTtXmA+0AW8CLy/qRWbmVlD+g36iPg+tefdAc6u0T+ASwdZl5mZNUk9I3orqVVbN/TfqQ/zjpvdpEpqq1Vfq49pZody0HegwQZ89X5aEbx91dfXNj8JmLWGg76DNCvgW73PgfKTgFlr+EvNOsCqrRtKFcjtMNyvv9lgeETfJNVB1KzRp8PtlVpxG5sNBx7RN0HPQG7GCNwh3ze/yjGrn0f0g1TPG4/1jj4dXI1r1RvKZjnxiH4I9Df69Oh0cHzbmfXNI/pBaDRgHEit0+irJ7PhxCP6QXColE/l1ZGfVM1e5qC3bDnszQoOesuaR/dmDnozs+w56G1Y8KjehjMHvQ0bDnsbrhz0Nqw47G04ctAPgkOjM/kNWhtuHPQD5KDofL4PbbjwJ2P74CDIn78rx4YDj+h74ZAfPnxfW+4c9GY47C1vDnqzxGFvuXLQ98LztsOTw95y5KDvg8PezHLgoO+Hw3748ajecuOgNzPLnIPezCxzDvo6ePpm+PH0jeXEQW9mljkHvZlZ5voNekljJP1Y0iOSnpB0VWqfKWmdpE2S7pR0WGofnda70vYZrb0KQ8PTN2bWqeoZ0e8HzoqI1wGzgXMlzQWuBr4UEbOA54FLUv9LgOcj4tXAl1I/MzNrk36DPgr70uqo9BPAWcDy1L4MOD8tL0jrpO1nS1LTKjYzs4bUNUcvaYSkDcAOYDXwc2B3RBxMXbqBqWl5KrAFIG3fA0yqsc/FktZLWn+A/YO7FmZm1qu6gj4ifhsRs4FpwKnAa2t1S5e1Ru9xSEPE0oiYExFzRjG63nrNzKxBDZ11ExG7gfuBucB4SZV/XDIN2JqWu4HpAGn7UcCuZhTbTj6vevjxfW65qOesm6MljU/LrwLeBGwE1gIXpG6LgHvS8oq0Ttp+X0QcMqI3M7OhUc+IfgqwVtKjwAPA6ohYCVwOXCapi2IO/qbU/yZgUmq/DFjS/LKHlkd2w5fve8tBv/8zNiIeBU6u0f4UxXx9z/ZfAxc2pTozMxs0fzK2Hx7RmVmnc9D3w5+INbNO56A364df1Vmnc9DXYd5xsz2yN7OO5aBvgAPfzDqRg34AHPjDj6dvrJP1e3ql9W6gYe/QMLOh5KBvg3qfIPyEUC6rtm7wKznrSJ66KTFPEZlZMzjozRrgV1nWiRz0HcCj+nJx2FuncdCbmWXOQW9mljkHvZlZ5hz0ZgPgeXrrJA56swFy2FuncNCbmWXOQW82CB7VWyfwVyDYkPLXP5gNPQe9DVorPtDVc59lDn5/B46VnadubFAccGbl56DvAGUdzQ5lyJf9CaWs95EZOOhLr6wBUvbgNbOXOeitY/jJxWxgHPRmTVLWV19mDnrrGA5Ss4Fx0JeYg63z+D6zMnLQmzWZw97KxkFfUg6Ll63auqHjbo9Oq9fy5qAvIYfEy3xbmA1e3UEvaYSkhyWtTOszJa2TtEnSnZIOS+2j03pX2j6jNaXnp5NGrkNRZ6fcFmZl18h33XwE2AiMS+tXA1+KiDsk3QhcAtyQLp+PiFdLWpj6vbOJNWdnsIFW6/zyoQpin9tuVn51Bb2kacBbgM8Dl0kScBbwrtRlGXAlRdAvSMsAy4F/kqSIiOaVnYfBhHF/AVvZ3orAd7ibdZZ6R/TXAZ8Ajkzrk4DdEXEwrXcDU9PyVGALQEQclLQn9d/ZlIozMdAAbmfIDvWx5x0329M3Zk3Qb9BLeiuwIyIelHRmpblG16hjW/V+FwOLAcYwtq5ih7N2j6LbffxO49vLyqSeEf0ZwNslzQfGUMzRXweMlzQyjeqnAVtT/25gOtAtaSRwFLCr504jYimwFGCcJg6raZ3+RqllC4l2v4oY6uknv4qw3PR71k1EXBER0yJiBrAQuC8i3g2sBS5I3RYB96TlFWmdtP0+z8/XZ95xs5seqmV70hiIZl6Hem7jHG4zs2qD+Q9TlwN3SPoc8DBwU2q/CbhVUhfFSH7h4ErMT3WQDMWZK4MZFZcl9HreZoP5/Ub6e3RvOWgo6CPifuD+tPwUcGqNPr8GLmxCbcNCWYK0lrLW1jOEa4VyWWs3aweVYVZlnCbG63V2u8vIXiOjUwflKzU6svftZ0Phe7H8wYiY018/fwXCMFJP+LTifQIza6/BzNFbB3KIt55vYysbj+jNzDLnoDczy5yD3qyJPG1jZeSgN2sSh7yVlYPerA7+NK11Mp91Y1Ynh7l1Ko/ozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwyp4hodw1I2gs82e46ejEZ2NnuIvpQ5vpc28C4toErc32tqO34iDi6v05l+VeCT0bEnHYXUYuk9WWtDcpdn2sbGNc2cGWur521eerGzCxzDnozs8yVJeiXtruAPpS5Nih3fa5tYFzbwJW5vrbVVoo3Y83MrHXKMqI3M7MWaXvQSzpX0pOSuiQtacPxvyZph6THq9omSlotaVO6nJDaJen6VOujkk5pcW3TJa2VtFHSE5I+Upb6JI2R9GNJj6TarkrtMyWtS7XdKemw1D46rXel7TNaVVtVjSMkPSxpZQlr2yzpMUkbJK1PbW2/X9PxxktaLumn6bF3Whlqk3Riur0qPy9I+mgZakvH++v0t/C4pNvT30g5HnMR0bYfYATwc+AE4DDgEeCkIa7hjcApwONVbdcAS9LyEuDqtDwf+A4gYC6wrsW1TQFOSctHAj8DTipDfekYR6TlUcC6dMy7gIWp/Ubgr9LyB4Eb0/JC4M4huG8vA74OrEzrZaptMzC5R1vb79d0vGXAB9LyYcD4stRWVeMIYDtwfBlqA6YCvwBeVfVYe19ZHnMtv0P6uXFOA1ZVrV8BXNGGOmbwyqB/EpiSlqdQnOcP8M/ARbX6DVGd9wDnlK0+YCzwEPB6ig+EjOx5/wKrgNPS8sjUTy2saRqwBjgLWJn+2EtRWzrOZg4N+rbfr8C4FFgqW2096nkz8IOy1EYR9FuAiekxtBKYV5bHXLunbio3TkV3amu3YyNiG0C6PCa1t63e9NLuZIqRcynqS1MjG4AdwGqKV2e7I+JgjeP/rra0fQ8wqVW1AdcBnwBeSuuTSlQbQADflfSgpMWprQz36wnAs8C/pmmvf5F0eElqq7YQuD0tt722iPgl8EXgaWAbxWPoQUrymGt30KtGW5lPA2pLvZKOAL4JfDQiXuira422ltUXEb+NiNkUo+dTgdf2cfwhq03SW4EdEfFgdXMfx2/H/XpGRJwCnAdcKumNffQdyvpGUkxl3hARJwO/opgO6c2Q33ZpnvvtwDf661qjrVWPuQnAAmAmcBxwOMV929vxh/R2a3fQdwPTq9anAVvbVEu1ZyRNAUiXO1L7kNcraRRFyN8WEXeXrT6AiNgN3E8xDzpeUuWrNaqP/7va0vajgF0tKukM4O2SNgN3UEzfXFeS2gCIiK3pcgfwLYonyjLcr91Ad0SsS+vLKYK/DLVVnAc8FBHPpPUy1PYm4BcR8WxEHADuBk6nJI+5dgf9A8Cs9M70YRQvx1a0uSYoaliUlhdRzI1X2i9O7+bPBfZUXjK2giQBNwEbI+LaMtUn6WhJ49Pyqyge6BuBtcAFvdRWqfkC4L5IE5TNFhFXRMS0iJhB8Zi6LyLeXYbaACQdLunIyjLFfPPjlOB+jYjtwBZJJ6ams4GflKG2Khfx8rRNpYZ21/Y0MFfS2PR3W7ndSvGYa+kbJnW+iTGf4mySnwOfasPxb6eYUztA8Sx7CcVc2RpgU7qcmPoK+HKq9TFgTotrewPFy7lHgQ3pZ34Z6gP+CHg41fY48OnUfgLwY6CL4qX16NQ+Jq13pe0nDNH9eyYvn3VTitpSHY+knycqj/sy3K/peLOB9em+/TYwoUS1jQWeA46qaitLbVcBP01/D7cCo8vymPMnY83MMtfuqRszM2sxB72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5ll7v8BaDbLJy1a0MIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADrCAYAAABn7V3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFURJREFUeJzt3XuwnHV9x/H3p7lBuCUhwIQkNUEzFsZqoBkMlzoOYAOREtpCDV6IDk5mLLZa2rFQHSsz2hF1kKFVbFqsAZWLiBIpToCAWqhEAoSbERMgwjGBEEkCeEGC3/7x/FaWzZ49u3v28uzvfF4zO/s8v+d3nue7l/PZ3/72pojAzMzy9Qf9LsDMzLrLQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz01lOS3ilpnaQXJG2V9F1Jx1dtP0LSKkm7JD0v6XZJx1ZtnyMpJN1bs9/pkn4raXNV22ZJv07H2iHpfyTNrvm7YyXdlo61S9J3JB3RoP73Srqj5hi/lTS9pt/6VOecmvZPpPaj6+x7hqT/lLQl1fyYpK9I+qOay/5Czekdw17hZjjorYcknQdcAvwrcAjwh8AXgSVp+2uBO4EHgbnAocC3gJslHVOzu30kvaFq/Z3A43UO++cRsS8wA3ga+Leqeo4BbgZuSMeaC9wP3CnpsBYu2uPAWVX7/WNg79pOkgS8B3gWWFaz7UDg/4DJwJ8C+wFHAd8H3lazqykRsW/V6ZoWarWxKCJ88qnrJ+AA4AXgzAZ9rgRuqtN+GfCDtDwHCOBjwGer+qwDPgpsrmrbDJxUtb4Y+GnV+v8CX6xzvO8CVwxT43uBO2qO8THg7qq2z6VaAphT1f4W4NfAu4FfABOrtn2S4kHmDxpcP5XLPr7ft6dPg3XyiN565RhgL4oR+nDeBnyjTvu1wHGSJle1fRVYKmmcpMMpRsBrh9tx+tt3AHdVrR/b4Hi1o+hG7gL2l3S4pHHpOF+t028Z8B2gMgI/tWrbScC3IuJ3LRz3VdK02APt/r3ly0FvvXIgsD0idjfoMx3YWqd9K8V9dWpV2xDwCEVALgOuGGaf35a0E3iOIrw/m9qnpX0Od7zpddobuRI4Ox3jJ8DPqzemB5Yzga9HxEvAdbx6+mY68FRV/9Mk7UyvHdxcc6ztaVvldDhARHw9It7YYt02BozvdwE2ZvwCmC5pfIOw304xl15rBvA7YAdwcFX7FRRTKcdSTIvMq/O3p0fErWmkvQT4fnqxdUfa5wyKYK493vZmLlSVK4EfUMzz13vQ+QtgN3BTWv8acKukgyLiGYrr5/eXPSJWAVMkvZ9iqqfa9BEeMM1exSN665UfAr8BTm/Q51aKUW+tvwZ+GBG/qmn/JvB24LGI+Fmjg0fEyxFxPfAycHxE/DLVNNzx1jTaX539/4ziRdnFwPV1uiwD9gWekPQUxZTRBF55EXcNcLok/09ax/lOZT0REbuAjwNfkHS6pMmSJkg6RdJnUrcLgWMlfUrSNEn7SfpbiimRf6qzz18CJwDvH+n4KiyhmP7ZkJrPB5ZJ+rt0rKmSPknxesKFbVzMc4ATUl3Vx54JnEgxJz8/nd4EXMQr0zcXp9qulPTaVO9+qa/ZqDjorWci4mLgPIp3qTwDPAl8EPh22r4ROJ4iBDdTzJX/FbAoIu4cZp/rIuLRBof9jqQXKOboPwUsi4iH09/eASwC/jId62fAkRQj/o1tXL5HI2JdnU3vAdZHxM0R8VTlBFwKvFHSGyJiO7CQ4lnPHcDzwHqKF5k/ULO/nTXvoz8PQNK7JD3cat2WP0X4h0fMzHLmEb2ZWea6EvSSTpb0iKRNks7vxjHMzKw5HZ+6SW9j+ynF+4mHgLuBsyLixx09kJmZNaUbI/qjgU0R8VhE/Ba4mvRdJmZm1nvdCPqZFO+mqBhKbWZm1gfd+GSs6rTtMT8kaTmwHGAc4/5kMvt3oRQzs3w9z47tEXHQSP26EfRDQPV3fs8CttR2iogVwAqA/TUt3qwTu1CKmVm+bo3rGn4ivKIbUzd3A/MkzZU0EVgKrOrCcczMrAkdH9FHxG5JHwRWA+OAL1c+iWhmZr3XlW+vjIibeOVb+szMrI/8yVgzs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPL3IhBL+nLkrZJeqiqbZqkWyRtTOdTU7skXSppk6QHJB3VzeLNzGxkzYzovwKcXNN2PrAmIuYBa9I6wCnAvHRaDlzWmTLNzKxdIwZ9RPwAeLameQmwMi2vBE6var8iCncBUyTN6FSxZmbWunbn6A+JiK0A6fzg1D4TeLKq31Bq24Ok5ZLWSVr3Ei+2WYaZmY2k0y/Gqk5b1OsYESsiYkFELJjApA6XYWZmFe0G/dOVKZl0vi21DwGzq/rNAra0X56ZmY1Wu0G/CliWlpcBN1S1n53efbMQ2FWZ4jEzs/4YP1IHSVcBbwWmSxoC/gX4NHCtpHOAJ4AzU/ebgMXAJuBXwPu6ULOZmbVgxKCPiLOG2XRinb4BnDvaoszMrHP8yVgzs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMjdi0EuaLel2SRskPSzpQ6l9mqRbJG1M51NTuyRdKmmTpAckHdXtC2FmZsNrZkS/G/iHiDgcWAicK+kI4HxgTUTMA9akdYBTgHnptBy4rONVm5lZ00YM+ojYGhH3puXngQ3ATGAJsDJ1WwmcnpaXAFdE4S5giqQZHa/czMya0tIcvaQ5wJHAWuCQiNgKxYMBcHDqNhN4surPhlJb7b6WS1onad1LvNh65WZm1pSmg17SvsA3gQ9HxHONutZpiz0aIlZExIKIWDCBSc2WYWZmLWoq6CVNoAj5r0XE9an56cqUTDrfltqHgNlVfz4L2NKZcs3MrFXNvOtGwOXAhoi4uGrTKmBZWl4G3FDVfnZ6981CYFdlisfMzHpvfBN9jgPeAzwoaX1q+2fg08C1ks4BngDOTNtuAhYDm4BfAe/raMVmZtaSEYM+Iu6g/rw7wIl1+gdw7ijrMjOzDmlmRG8ltXrL+pE7DWPRofM7WEl99errxXHN7NUc9ANoNAFfu49uBG+j+hpt84OAWXc46AdIJwK+3X1WQrgbNTRTix8EzNrnoB8A3QzXQalh9Zb1DnuzNjnoO6Q6CDsVSP0O17LpxnVsNhb4a4o7oDaQV29ZP+qQdsg31onr2GyscNCPUrsvPA7X3wHWGl9XZiNz0HdZM0HkcB8dX3dmjXmOfhSaDRgHUfd18+2iZoPOI/pRcKiUj6e/zPbkoLdsOezNCg56y5pH92YOejOz7DnoR8nz9IPBo3obyxz0o+QAGRy+rWysctDbmOKwt7HIQT8KDo3B5Bdobaxx0LfJQTH4fBvaWOFPxjZQGwSLDp3vcMiMv/7YxgKP6IdRL9Ad8nny7Wq5c9Cb4bC3vDnozRKHveXKQT8Mz9uOTQ57y5GDvgGHvZnlwEE/Aof92ONRveXGQW9mljkHvZlZ5hz0TfD0zdjj6RvLiYPezCxzDnozs8yNGPSS9pL0I0n3S3pY0oWpfa6ktZI2SrpG0sTUPimtb0rb53T3IvSGp2/MbFA1M6J/ETghIt4EzAdOlrQQuAj4fETMA3YA56T+5wA7IuJ1wOdTPzMz65MRgz4KL6TVCekUwAnAdal9JXB6Wl6S1knbT5SkjlVsZmYtaWqOXtI4SeuBbcAtwKPAzojYnboMATPT8kzgSYC0fRdwYJ19Lpe0TtK6l3hxdJfCzMyG1VTQR8TLETEfmAUcDRxer1s6rzd6jz0aIlZExIKIWDCBSc3Wa2ZmLWrpXTcRsRP4HrAQmCKp8sMls4AtaXkImA2Qth8APNuJYvvJ76see3ybWy6aedfNQZKmpOW9gZOADcDtwBmp2zLghrS8Kq2Ttt8WEXuM6M3MrDea+SnBGcBKSeMoHhiujYgbJf0YuFrSJ4H7gMtT/8uBKyVtohjJL+1C3T3lkZ2ZDbIRgz4iHgCOrNP+GMV8fW37b4AzO1KdmZmNmj8ZOwKP5s1s0DnoR+BPxJrZoHPQmzXgZ3SWAwd9ExYdOt8jezMbWA76FjjwzWwQOejb4MAfWzx9Y4OumffR2zDaDXsHh5n1koO+D1p5gPCDgpmNlqduSs5TROXgB1wbZA56syY57G1QOegHgEf1ZjYaDnqzFnhUb4PIQW9mljkHvZlZ5hz0Zi3y9I0NGge9mVnmHPTWMn8FhNlgcdBb22oDfyyFv6dvbJD4KxCsZau3rB824KuX64XhaB4MHK5m7VFE9LsG9te0eLNO7HcZpVemoOvX6L1M1wGMrWcxVj63xnX3RMSCkfp56sbMLHMOemtLv0bWZRtBl+0Zhlk9DvoBUbZAKVvg9lPZbhuzWg56GzhlfJBx2FuZOejNOsRhb2XloB8ADhAzGw0H/RhRxumO0Sjr5fGDspWRg34MKWs45sZhb2XjT8aW3GhDozbcFx06fyCDaNBqrv30sFk/eURfYt0Kt0ELoEELebOyaTroJY2TdJ+kG9P6XElrJW2UdI2kial9UlrflLbP6U7peetUuHUrJHsRvqu3rHfIm3VAK1M3HwI2APun9YuAz0fE1ZK+BJwDXJbOd0TE6yQtTf3e0cGas9dquA03Qm+0n0GdwjGz1jUV9JJmAW8HPgWcJ0nACcA7U5eVwCcogn5JWga4Dvh3SYoyfHtaybUSvM1Mv3RriqZXUz9+MDLrjGZH9JcAHwH2S+sHAjsjYndaHwJmpuWZwJMAEbFb0q7Uf3tHKs5QpwN+NPvv9LE7cUyHvdnojBj0kk4FtkXEPZLeWmmu0zWa2Fa93+XAcoC9mNxUsWNZuyE7yCHfbZXL1I0HkhyvLxtczYzojwNOk7QY2Itijv4SYIqk8WlUPwvYkvoPAbOBIUnjgQOAZ2t3GhErgBVQfB/9aC/IoOr0j3N0Q7/r6caovtEvY/kZhOVmxHfdRMQFETErIuYAS4HbIuJdwO3AGanbMuCGtLwqrZO23+b5+fpqA6Ubv8Xa75Aum2auY19nlpuWfmEqTd38Y0ScKukw4GpgGnAf8O6IeFHSXsCVwJEUI/mlEfFYo/2O5V+Y6tUHa9odpZYx9Nq5LL38CcMyXmeWp2Z/Yco/JTiG5BZYlctTb669G7U3e/2V/XqzfDjorS6H1eg0c/35urNe8W/GWl3NzE87qMzy4i81G4Mc5O3xu3FsUHlEb2aWOQe9WRM8mrdB5qA36yBPi1kZOejNOsQhb2XloDdrwkjvRnLIW5n5XTdmLXCg2yDyiN7MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHOKiH7XgKTngUf6XccwpgPb+11EA2Wuz7W1x7W1r8z1daO210TEQSN1KstPCT4SEQv6XUQ9ktaVtTYod32urT2urX1lrq+ftXnqxswscw56M7PMlSXoV/S7gAbKXBuUuz7X1h7X1r4y19e32krxYqyZmXVPWUb0ZmbWJX0PekknS3pE0iZJ5/fh+F+WtE3SQ1Vt0yTdImljOp+a2iXp0lTrA5KO6nJtsyXdLmmDpIclfags9UnaS9KPJN2farswtc+VtDbVdo2kial9UlrflLbP6VZtVTWOk3SfpBtLWNtmSQ9KWi9pXWrr++2ajjdF0nWSfpLue8eUoTZJr0/XV+X0nKQPl6G2dLy/T/8LD0m6Kv2PlOM+FxF9OwHjgEeBw4CJwP3AET2u4S3AUcBDVW2fAc5Py+cDF6XlxcB3AQELgbVdrm0GcFRa3g/4KXBEGepLx9g3LU8A1qZjXgssTe1fAj6Qlv8G+FJaXgpc04Pb9jzg68CNab1MtW0Gpte09f12TcdbCbw/LU8EppSltqoaxwFPAa8pQ23ATOBxYO+q+9p7y3Kf6/oNMsKVcwywumr9AuCCPtQxh1cH/SPAjLQ8g+J9/gD/AZxVr1+P6rwBeFvZ6gMmA/cCb6b4QMj42tsXWA0ck5bHp37qYk2zgDXACcCN6Z+9FLWl42xmz6Dv++0K7J8CS2WrraaePwPuLEttFEH/JDAt3YduBBaV5T7X76mbypVTMZTa+u2QiNgKkM4PTu19qzc9tTuSYuRcivrS1Mh6YBtwC8Wzs50RsbvO8X9fW9q+CziwW7UBlwAfAX6X1g8sUW0AAdws6R5Jy1NbGW7Xw4BngP9O017/JWmfktRWbSlwVVrue20R8XPgc8ATwFaK+9A9lOQ+1++gV522Mr8NqC/1StoX+Cbw4Yh4rlHXOm1dqy8iXo6I+RSj56OBwxscv2e1SToV2BYR91Q3Nzh+P27X4yLiKOAU4FxJb2nQt5f1jaeYyrwsIo4EfkkxHTKcnl93aZ77NOAbI3Wt09at+9xUYAkwFzgU2Ifith3u+D293vod9EPA7Kr1WcCWPtVS7WlJMwDS+bbU3vN6JU2gCPmvRcT1ZasPICJ2At+jmAedIqny1RrVx/99bWn7AcCzXSrpOOA0SZuBqymmby4pSW0ARMSWdL4N+BbFA2UZbtchYCgi1qb16yiCvwy1VZwC3BsRT6f1MtR2EvB4RDwTES8B1wPHUpL7XL+D/m5gXnpleiLF07FVfa4JihqWpeVlFHPjlfaz06v5C4FdlaeM3SBJwOXAhoi4uEz1STpI0pS0vDfFHX0DcDtwxjC1VWo+A7gt0gRlp0XEBRExKyLmUNynbouId5WhNgBJ+0jar7JMMd/8ECW4XSPiKeBJSa9PTScCPy5DbVXO4pVpm0oN/a7tCWChpMnp/7ZyvZXiPtfVF0yafBFjMcW7SR4FPtqH419FMaf2EsWj7DkUc2VrgI3pfFrqK+ALqdYHgQVdru14iqdzDwDr02lxGeoD3gjcl2p7CPh4aj8M+BGwieKp9aTUvlda35S2H9aj2/etvPKum1LUluq4P50ertzvy3C7puPNB9al2/bbwNQS1TYZ+AVwQFVbWWq7EPhJ+n+4EphUlvucPxlrZpa5fk/dmJlZlznozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHP/DwwCkjS4Sl7RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADrCAYAAABn7V3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFhpJREFUeJzt3X+wXGV9x/H3xyQEEEJIAjQkKQGJCv4gYApB0EECAikCHUBACsGJTWupg8YKoU4rdNpR1ApiO9goagREELBEhpafoa1YAkFDCAZMwJhcEwgREgIKJvDtH+dZWDd779292b179snnNbNzz3nOs3u+d8+5nz37nLN7FRGYmVm+3tTpAszMrL0c9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkHf5SStlPQ7SZskbZD0E0l/JelNVX2+I+n3kl6suj2Slk2UFJKG1nnsSyRtrrnfBkl/XNMWkl6qmn9fWuc/VT3WcEmfl7Qq1btc0mckqarPfZJeljShqu0YSSur5o9Mv+NGSc9Jul/Sn/Tx/LxV0g8krU/3WSJptqQhraqr5rl4LT1OZf7s1OdASfNTDZskLZD03qrHO0pST53675P0sTrbo7KtD+/jdz9P0o+r5lem/WBMTb/FaRtOrGm/JLUfWuexx0r6hqQ1qZ6n0jZ/e1pe2a9erLmd0Vu91j4O+jx8KCJ2BfYBvgBcBFxd0+eLEbFL1e2gBh/7hpr7jYyIVdVtqd9BVW3/W+dxfgBMA6YDuwLnALOAr9b0ewn4+3qFSBoB3AZ8DRgFjAMuBV7ppf9bgIXAauBdEbEbcDowJdXQkrpqnotVFNuj0nZdquN+4FFgX2Bv4IfAnX0FdS9uSOsZAyxI9Tfjl8BZlRlJ7wJ2qu2UXujOAZ4DZtQsGw38BNgZeB/F83YI8N/AsTUPNbJm/7mhyXqtBRz0GYmIjRExHzgDmCHpnZ2uCUDSNOCDwKkRsTQitkTEA8CfA+dL2r+q+5XAWTVtFW8FiIjrI+LViPhdRNwZEUt6WfWlwE8iYnZErE33fSIiPhIRG1pYV38uAf4vIj4bEc9FxKaIuBK4BrhsAI9HRGwBrgPGSdqjibteA5xbNT8D+G6dfu+jeEG6ADhT0g5Vyz4FvACcExFPRmFDRHw7Ir7W1C9ig8JBn6GIeBDoofhjLYNjgYURsbq6MSIWUtQ5rar518A3KMKx1i+AVyXNk3SCpN37We8xwE2DUFd/jqX+kfeNwBGSdm72AVPwngv8Bni+ibs+AIyQdEAavjoDuLZOvxnAj4DKEfiJVcuOAX4YEa81W3eFpI9I6u0F2lrMQZ+vNRTDGxV/m8Z1K7d5DT7Oh2vut2AAtYwB1vaybG1aXu3zwIckvaO6MSJeAI4EgiJ0n03j3nv18tij+1hvy+pqQG/rWUvxN9jfC1a1D0vaAPwO+AvgtHR034zKUf2xwOMUL2KvSy88pwPfi4jNFC+W1cM3Y4Cnq/qflPaNTZLurFnX+pr95wCAiPheRLy7ybptgBz0+RpHMb5a8eU0vl65zejtjjVurLnfBwZQy3pgbC/Lxqblr4uIZ4F/Bf6xtnNELIuI8yJiPPBOiuGFK3p57N/0sd6W1tWP3tYzFniN4oh8CzCsTp9hwOaq+RsjYiSwF7AUeE+TtUAR9B8BzqP+sM2fpXpuT/PXASdUDRH9wfMaEfNTTZ8Cqod4AMbU7D/LBlCvbSMHfYbSVSjjgB/313eQ3A0cVn3VCkC6mmMCcG+d+3wJ+AB9BFlEPA58hyLwe1vvqYNdVy/rOb1O+4cpxu5/S3ESd4ykysntygnRfYBf1d4xItYDfwlcIqmvF7OtRMSvKE7KTgduqdNlBrALsErS0xTDTsN44yTuPcApqrqyy8rNGyojkkZIOhH4PnBtRDzaxN2HS9qx6tayfSMi7qYIh5slvUPSEElTKY4Ur4qI5XXuswH4F+DCSpukt0v6tKTxaX4CRfg80MuqPwe8V9KXJP1Rus/+kq6VNLJVdTXg0lTHP0saJWlXSZ+gGD65KD3uKoorhC6TtIuk4cBnKI6s6/5+6YXujiZrqZgJHB0RL1U3ShpHcW7iRGByuh1EcdK48i7wKxTDTddIeosKu6a+VkIO+jz8SNImissIP0vxh/jRmj4X1lzPvL5m+YsU476V29Gp/Yw610LvOYAaT6W4HPC/0rqupbgE9BN93OerwKtV85uAw4CFkl6iCMClwKfr3TkingQOByYCj0naCNwMLEqP1aq6+pReMI6kCMyVFGPzpwLHRcT9VV3PAPYEVlCMm08DpkfEy308/JeAWc1uk3S1zKI6i84BFqermZ6u3CiuOnq3pHemdxNTgZcp3jVuAhZTXGb58ZrH21Cz78wGkHS2pMeaqdkGTv7HI2ZmefMRvZlZ5toS9JKOl/SEpBWS5rRjHWZm1piWD92kD2H8guIa3R7gIeCsiPh5S1dkZmYNaccR/aHAioh4KiJ+T3EFyMltWI+ZmTWgHUE/juLqj4qe1GZmZh2w1VfTtoDqtG01PiRpFsW3BDKEIe/ZmRFtKMXMLF+beH59RPT7pXbtCPoeik8VVoyn+N6VPxARc4G5ACM0Kg7TtNouZmbWh7vjpq0+NV1PO4ZuHgImSdo3fcPemcD8NqzHzMwa0PIj+ojYIulvKD6aPQT4VkT4E3BmZh3SjqEbIuJ23vjmOzMz6yB/MtbMLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy12/QS/qWpHWSlla1jZJ0l6Tl6efuqV2SrpS0QtISSYe0s3gzM+tfI0f03wGOr2mbA9wTEZOAe9I8wAnApHSbBVzVmjLNzGyg+g36iPgf4Lma5pOBeWl6HnBKVft3o/AAMFLS2FYVa2ZmzRvoGP1eEbEWIP3cM7WPA1ZX9etJbVuRNEvSIkmLNvPKAMswM7P+tPpkrOq0Rb2OETE3IqZExJRhDG9xGWZmVjHQoH+mMiSTfq5L7T3AhKp+44E1Ay/PzMy21UCDfj4wI03PAG6taj83XX0zFdhYGeIxM7POGNpfB0nXA0cBYyT1AJ8DvgDcKGkmsAo4PXW/HZgOrAB+C3y0DTWbmVkT+g36iDirl0XT6vQN4PxtLcrMzFrHn4w1M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHP9Br2kCZIWSFom6TFJF6T2UZLukrQ8/dw9tUvSlZJWSFoi6ZB2/xJmZta7Ro7otwCfjogDgKnA+ZIOBOYA90TEJOCeNA9wAjAp3WYBV7W8ajMza1i/QR8RayPip2l6E7AMGAecDMxL3eYBp6Tpk4HvRuEBYKSksS2v3MzMGtLUGL2kicDBwEJgr4hYC8WLAbBn6jYOWF11t57UVvtYsyQtkrRoM680X7mZmTWk4aCXtAtwM/DJiHihr6512mKrhoi5ETElIqYMY3ijZZiZWZMaCnpJwyhC/rqIuCU1P1MZkkk/16X2HmBC1d3HA2taU66ZmTWrkatuBFwNLIuIr1Qtmg/MSNMzgFur2s9NV99MBTZWhnjMzGzwDW2gzxHAOcCjkhantr8DvgDcKGkmsAo4PS27HZgOrAB+C3y0pRWbmVlT+g36iPgx9cfdAabV6R/A+dtYl5mZtYg/GbudumPN4v47mVkWHPTbqeP2ntzpEsxskDjorSF3rFnsdwFmXaqRk7Fmfgdg1sV8RG9mljkHvZlZ5hz0beZxbTPrNAd9mx2392SfyDSzjvLJ2EHgE5lm1kk+ojczy5yD3swscw56M7PMOejNzDLnoN9GvprGzMrOQb+NfEWNmZWdg97MLHMOejOzzDnozcwy56Bvgk+8mlk3ctA3wSdezawbOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy1y/QS9pR0kPSnpE0mOSLk3t+0paKGm5pBsk7ZDah6f5FWn5xPb+CmZm1pdGjuhfAY6OiIOAycDxkqYClwGXR8Qk4HlgZuo/E3g+IvYHLk/9zMysQ/oN+ii8mGaHpVsARwM3pfZ5wClp+uQ0T1o+TZJaVrGZmTWloTF6SUMkLQbWAXcBTwIbImJL6tIDjEvT44DVAGn5RmB0ncecJWmRpEWbeWXbfgszM+tVQ0EfEa9GxGRgPHAocEC9bulnvaP32KohYm5ETImIKcMY3mi9ZmbWpKauuomIDcB9wFRgpKShadF4YE2a7gEmAKTluwHPtaJYMzNrXiNX3ewhaWSa3gk4BlgGLABOS91mALem6flpnrT83ojY6ojezMwGRyNH9GOBBZKWAA8Bd0XEbcBFwGxJKyjG4K9O/a8GRqf22cCc1pdtNjj87yMtB0P76xARS4CD67Q/RTFeX9v+MnB6S6ozM7Nt5k/GmpllzkFvZpY5B71ZH47be7LH6a3rOejNzDLnoDczy5yD3qwfHr6xbuegNzPLnIO+xHwUWS7eHtatHPQldtzekztdgiXeFtbNHPRmDfJYvXUrB71Zkxz21m0c9GZN8BCOdSMHvZlZ5hz0ZmaZc9CbNcknZa3bOOjNBshhb93CQW9Nu2PNYoecWRdx0NuA1Qb+9hT+latvtqff2bpXv/9K0KxW7Rh1b9PbcilivQD1pY1mA6OI6HQNjNCoOEzTOl1Gqd2xZnGpgq5Vgd7s+sr0HEB567Ltw91x08MRMaW/fh66sW3igDMrPwd9FyjjOPBxe08e1JAv65h4Wesyq+agLzkPDZSft42VnYPeukaZj54d9lZmDnozs8w56LuAjxYLZTySN+sGDvoSa2Ww5RaSuf0+Zu3koN+OOBzNtk/+ZGxJtepqm9pwL9sHrxpRqbnb6jYrCx/Rl1C7L6nspiP7bnxhMiubhoNe0hBJP5N0W5rfV9JCScsl3SBph9Q+PM2vSMsntqf0/FR/SVirwq3bQ7Lb6zcrg2aO6C8AllXNXwZcHhGTgOeBmal9JvB8ROwPXJ76WR9qvwWyFeHW31F7K47qu+mdgdn2rKGglzQe+FPgm2lewNHATanLPOCUNH1ymictn5b6W416Ad/qI/l2hnG7j7b9QmLWGo2ejL0CuBDYNc2PBjZExJY03wOMS9PjgNUAEbFF0sbUf31LKs7EYH77Y7cOf1S+Drlb6zcri36P6CWdCKyLiIerm+t0jQaWVT/uLEmLJC3azCsNFWvNc0j2zv8py7YXjRzRHwGcJGk6sCMwguIIf6SkoemofjywJvXvASYAPZKGArsBz9U+aETMBeZC8X302/qLdJPB/i73btbOo3o/97a96PeIPiIujojxETEROBO4NyLOBhYAp6VuM4Bb0/T8NE9afm+U4b+blJCDpjF+nsy2zbZcR38RMFvSCoox+KtT+9XA6NQ+G5izbSXmxx/+6R4DGdrxcJCVTVOfjI2I+4D70vRTwKF1+rwMnN6C2qyFfFJz4Pw/Aazb+ZOx24naf+htjal+9+Xnz7qVg3474rA32z456LczHn4YuEafOz/HVjYOejOzzDnozRrgo3TrZg56M7PMOejNzDLnoDdrkK9Ysm7loDdrkMfprVs56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMqeI6HQNSNoEPNHpOnoxBljf6SL6UOb6XNvAuLaBK3N97ahtn4jYo79OQ1u80oF6IiKmdLqIeiQtKmttUO76XNvAuLaBK3N9nazNQzdmZplz0JuZZa4sQT+30wX0ocy1Qbnrc20D49oGrsz1day2UpyMNTOz9inLEb2ZmbVJx4Ne0vGSnpC0QtKcDqz/W5LWSVpa1TZK0l2Slqefu6d2Sboy1bpE0iFtrm2CpAWSlkl6TNIFZalP0o6SHpT0SKrt0tS+r6SFqbYbJO2Q2oen+RVp+cR21VZV4xBJP5N0WwlrWynpUUmLJS1KbR3frml9IyXdJOnxtO8dXobaJL0tPV+V2wuSPlmG2tL6PpX+FpZKuj79jZRjn4uIjt2AIcCTwH7ADsAjwIGDXMP7gUOApVVtXwTmpOk5wGVpejrwn4CAqcDCNtc2FjgkTe8K/AI4sAz1pXXskqaHAQvTOm8EzkztXwc+nqb/Gvh6mj4TuGEQtu1s4HvAbWm+TLWtBMbUtHV8u6b1zQM+lqZ3AEaWpbaqGocATwP7lKE2YBzwS2Cnqn3tvLLsc23fIP08OYcDd1TNXwxc3IE6JvKHQf8EMDZNj6W4zh/g34Gz6vUbpDpvBY4tW33AzsBPgcMoPhAytHb7AncAh6fpoamf2ljTeOAe4GjgtvTHXora0npWsnXQd3y7AiNSYKlstdXU80Hg/rLURhH0q4FRaR+6DTiuLPtcp4duKk9ORU9q67S9ImItQPq5Z2rvWL3prd3BFEfOpagvDY0sBtYBd1G8O9sQEVvqrP/12tLyjcDodtUGXAFcCLyW5keXqDaAAO6U9LCkWamtDNt1P+BZ4Ntp2Oubkt5cktqqnQlcn6Y7XltE/Br4MrAKWEuxDz1MSfa5Tge96rSV+TKgjtQraRfgZuCTEfFCX13rtLWtvoh4NSImUxw9Hwoc0Mf6B602SScC6yLi4ermPtbfie16REQcApwAnC/p/X30Hcz6hlIMZV4VEQcDL1EMh/Rm0J+7NM59EvCD/rrWaWvXPrc7cDKwL7A38GaKbdvb+gf1eet00PcAE6rmxwNrOlRLtWckjQVIP9el9kGvV9IwipC/LiJuKVt9ABGxAbiPYhx0pKTKV2tUr//12tLy3YDn2lTSEcBJklYC36cYvrmiJLUBEBFr0s91wA8pXijLsF17gJ6IWJjmb6II/jLUVnEC8NOIeCbNl6G2Y4BfRsSzEbEZuAV4LyXZ5zod9A8Bk9KZ6R0o3o7N73BNUNQwI03PoBgbr7Sfm87mTwU2Vt4ytoMkAVcDyyLiK2WqT9Iekkam6Z0odvRlwALgtF5qq9R8GnBvpAHKVouIiyNifERMpNin7o2Is8tQG4CkN0vatTJNMd68lBJs14h4Glgt6W2paRrw8zLUVuUs3hi2qdTQ6dpWAVMl7Zz+bivPWyn2ubaeMGnwJMZ0iqtJngQ+24H1X08xpraZ4lV2JsVY2T3A8vRzVOor4N9SrY8CU9pc25EUb+eWAIvTbXoZ6gPeDfws1bYU+IfUvh/wILCC4q318NS+Y5pfkZbvN0jb9yjeuOqmFLWlOh5Jt8cq+30Ztmta32RgUdq2/wHsXqLadgZ+A+xW1VaW2i4FHk9/D9cAw8uyz/mTsWZmmev00I2ZmbWZg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy9/9EQG49RxqcpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get from contourpoints a image --> Example\n",
    "#print(translation_pred)\n",
    "\n",
    "contour_img = np.zeros(image.shape)\n",
    "contour_img = cv2.fillPoly(contour_img, np.int32([translation_pred]), color=(255,255,255))\n",
    "contour_img = cv2.cvtColor(contour_img.astype(np.float32), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "osvos_img = cv2.imread('OSVOS_PyTorch/models/Results/bear/00001.png')\n",
    "osvos_img = cv2.cvtColor(osvos_img.astype(np.float32), cv2.COLOR_RGB2GRAY)\n",
    "osvos_img = np.where(osvos_img >= 256/2, 255, 0)\n",
    "\n",
    "combo_img = np.where(np.logical_and(osvos_img==255, contour_img==255), 1, 0)\n",
    "deletions_contour_img = np.where(np.logical_and(osvos_img!=255, contour_img==255), 1, 0)\n",
    "deletions_osvos_img = np.where(np.logical_and(osvos_img==255, contour_img!=255), 1, 0)\n",
    "\n",
    "plt.title('CONTOUR IMAGE:')\n",
    "plt.imshow(contour_img)\n",
    "plt.show()\n",
    "\n",
    "plt.title('OSVOS IMAGE:')\n",
    "plt.imshow(osvos_img)\n",
    "plt.show()\n",
    "\n",
    "plt.title('COMBO IMAGE:')\n",
    "plt.imshow(combo_img)\n",
    "plt.show()\n",
    "\n",
    "plt.title('DELETIONS CONTOUR IMAGE:')\n",
    "plt.imshow(deletions_contour_img)\n",
    "plt.show()\n",
    "\n",
    "plt.title('DELETIONS OSVOS IMAGE:')\n",
    "plt.imshow(deletions_osvos_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Load model and run the solver\n",
    "model = Net(in_channels=train[0].num_features, \n",
    "            out_channels=train[0].y.shape[1])\n",
    "print(model)\n",
    "model.double()\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), \n",
    "                       eps=1e-8, weight_decay=0.0)\n",
    "train_loss_history = train_net(model, train_loader, val_loader, optimizer, criterion,\n",
    "                               num_epochs=10, log_nth=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_net(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
